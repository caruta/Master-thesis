\documentclass[a4paper,11pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{multirow}
\usepackage{hyphenat}
\usepackage{sectsty}
\usepackage{amsmath}
\usepackage{bm}
%\usepackage[style=alphabetic]{biblatex}
%\usepackage[dvipsnames]{xcolor}
%\sectionfont{\bfseries\Large\raggedright}
\allsectionsfont{\raggedright}
\graphicspath{ {images/} }

%\usepackage[T1]{fontenc}

\def\double{\baselineskip 24pt \lineskip 10pt}
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
\renewcommand{\thefigure}{\arabic{section}.\arabic{figure}}
\textheight 9.5in \textwidth 6in \oddsidemargin 25pt\topmargin
-40pt

\def\baselinestretch{1.2}
\parskip 0.2cm

%\usepackage[autostyle,italian=giullemets]{csquotes}
%\usepackage[babel]{csquotes}
%\usepackage{biblatex}
%\bibliography{biblio.bib}

\begin{document}

%FRONTESPIZIO

\thispagestyle{empty}
\begin{center}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.3]{logoUniba}
\end{figure}
%\begin{center}
{\normalsize DIPARTIMENTO INTERATENEO DI FISICA \textquotedblleft M. MERLIN"} \\
\vspace{0.5cm}
\hrule \vspace{0.5cm}

%\end{center}
%
%
%% Titolo tesi
%%\vspace{1.0cm}
%\begin{center}
{\bf {\large{Tesi di laurea Magistrale in \\ \textquotedblleft Nuclear, Subnuclear and Astroparticle Physics"}}} \\
\vspace{2cm}
{\bf{\large { \Huge{Search for $\tau \rightarrow 3\mu$ decays\\ using $\tau$ leptons produced \\in D and B mesons decays \\in CMS experiment at LHC\\}}}}
\end{center}

% Relatrici & laureanda
\vspace{3.5cm}
\begin{flushleft}
{ Relatrici:} \\
{\bf Dott.ssa Anna Colaleo} 
\hspace{6.2cm} {Laureanda:} \\
{\bf Dott.ssa Rosamaria Venditti} 
\hspace{5cm} {\bf Caterina Aruta}
\end{flushleft}
%
%% Laureanda
%\begin{flushleft}
%\hspace{11cm} {\bf Laureanda:} \\
%\hspace{11cm} {\bf Caterina Aruta}
%\end{flushleft}

% Anno accademico
\vspace{2cm}
\begin{center}
\hrule \vspace{0.05cm}
\hrule \vspace{0.15cm}
{\bf {\large{Anno Accademico 2018-2019}}} \\
\end{center}

\newpage
%\chapter*{Aknowledgments}
\tableofcontents 

%\chapter*{Introduction}


%%%%%%%%%%%%%%%%%%%%
\chapter{Standard Model and new physics search}

\section{The Standard Model}

\section{Physics Beyond the Standard Model}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\chapter{The CMS experiment at LHC}
The Large Hadron Collider (LHC) is currently the world's largest and most powerful particle collider ever built. Its main goal is to explore the physics at the TeV energy scale in order to test the predictions of the Standard Model and eventually reveal some violations than can be a hint of new physics, described by Beyond Standard Model theories.\\
After an overview of the accelerator, I will describe in detail the Compact Muon Solenoid (CMS) experiment, which is the one, among the experiments located around the LHC ring, that collected the data used in the analysis described in this thesis.

\section{The Large Hadron Collider}
The LHC is a proton-proton (pp) and heavy ions collider built by the European Organization for Nuclear Research (CERN) between 1998 and 2008 and situated beneath the France-Switzerland border near the city of Geneva \cite{ref30}. The accelerator, along with the detectors, is the product of an impressive effort that has required the collaboration of more than 100 countries with over 10 thousand scientists.
LHC is placed in a tunnel of 26.7 km in circumference, previously used for the Large Electron Positron (LEP) collider \cite{ref31}, with an average depth of about 100 metres underground. The whole accelerating system is made up of different stages and a complete scheme is shown in Fig. \ref{fig:LHC_complex}. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{LHC_complex}
	\caption{The different stages of CERN accelerator complex.}
	\label{fig:LHC_complex}
\end{figure}

The LHC tunnel contains two adjacent parallel beam pipes, kept at ultrahigh vacuum, in which particles travel in opposite directions around the ring and intersect in four points, where the collisions take place.
Around these crossing points the detectors are positioned, in order to record and later analyse all the possible information resulting from the scattering of the beams.\\
The main experiments present at LHC are: \emph{A ToroidaL ApparatuS} (ATLAS) \cite{ref34}, \emph{Compact Muon Solenoid} (CMS) \cite{ref32}, \emph{Large Hadron Collider beauty} experiment (LHCb) \cite{ref36} and \emph{A Large Ion Collider Experiment} (ALICE )\cite{ref35}.\\
The first two are general purpose detectors: after the search and discovery of the Higgs boson by both collaborations in 2012 \cite{ref1}\cite{ref2}\cite{ref3}, their main task is to study the production and decay of the discovered Higgs boson, to investigate its properties and to check if it is exactly the SM Higgs boson or one predicted by an extension of the SM.
In addition to this, several searches for physics beyond the SM are also part of their program, e.g. searches for supersymmetric particles.\\
The LHCb experiment is specialised on heavy flavour physics: it looks for indirect evidence of new physics in CP violation and rare decays of bottom and charm hadrons, in order to explain the large asymmetry between the amount of matter and anti-matter in the universe.\\
ALICE is a dedicated heavy-ion detector: it searches for evidence of the quark-gluon plasma, a presumed state of matter with asymptotically free quarks and gluons.

For proton-proton collisions, the designed LHC centre of mass energy ($\sqrt{s}$), which is simply the sum of the energies of the two interacting beams, is $\sqrt{s}$ = 14 TeV. Such high energy value can be reached, starting from $\sim$450 GeV (which is the energy that protons have when they are injected in the LHC ring) by accelerating particles using radiofrequency(RF) cavities. These RF cavities play also an important role in synchronizing temporally the protons, grouping them into discrete packets, called \emph{bunches}. Each of these bunches is made up of about $\mathrm{10^{11}}$ protons and a bunch collision takes place every 25 ns, providing an interaction rate of 40 MHz.
The beams are kept on their circular path by 1232 dipole magnets, while about 392 quadrupole magnets focus them spatially. There are also other kind of magnets used to “squeeze" the particles closer together in correspondence of the interactions points, to increase the chances of collisions. In total there are about 10000 superconducting magnets, which are constantly kept at a temperature of 1.9 K by a cooling system based on liquid helium.\\
The number of protons contained in each bunch ($N$), together with the number of bunches rotating in the accelerator ($n_{b}\sim$2500), the collision frequency ($f$) and the RMS of beam profile in the plane orthogonal to the beam direction ($\sigma_{xy}$), determines the \emph{luminosity} of the machine ($\mathcal{L}$), which is a parameter used to quantify the performance of a particle accelerator.
The luminosity is defined as the ratio between the event rate $R_{k}$ of a given process $k$ and the cross section characterizing that process $\sigma_{k}$ :
$ \mathcal{L} = \frac{R_{k}}{\sigma_{k}}$.

In particular, in the case of a collider with Gaussian-shaped beam bunches crossing with a small angle, like LHC, the luminosity can be computed by using the equation \ref{eq:Lumi}.

\begin{equation}
\mathcal{L} = \frac{f\ n_{b}\ N^{2}}{4 \pi\ \sigma_{xy}^{2}}
	\label{eq:Lumi}
\end{equation}

For what concerns proton-proton collisions, LHC was operated at $\sqrt{s}$ = 7 TeV in 2010 and 2011 and at $\sqrt{s}$ = 8 TeV in 2012, during LHC Run I data-taking. In 2013 there was a long shutdown to upgrade the accelerator.
In the LHC Run II data-taking, from 2015 to 2018, data were collected at a center of mass energy $\sqrt{s}$ = 13 TeV.\\ 
Moreover, for these kind of collisions the LHC designed luminosity is $10^{34}\ \mathrm{cm^{-2}\ s^{-1}}$, which was first reached in June 2016 and doubled in 2017.
Integrating this parameter with respect to time, the \emph{Integrated luminosity} is obtained. This quantity is correlated with the amount of data collected: the greater it is, the larger is the amount of data available. Therefore, in order to access rare processes (i.e. processes with very low cross sections), it is very important to maximize the luminosity of the accelerator. \\
Fig. \ref{fig:IntLumi_cumulative_total} shows the total integrated luminosity delivered by LHC and recorded by CMS experiment for proton-proton collisions since 2010.

\begin{figure}[h]
 \begin{minipage}[b]{7.5cm}
   \centering
   \includegraphics[width=7.6cm]{IntLumi_cumulative_peryear}
 \end{minipage}
% \ \hspace{0.5mm} \hspace{0.5mm} \
 \begin{minipage}[b]{7.5cm}
  \centering
   \includegraphics[width=7.6cm]{IntLumi_cumulative_total}
 \end{minipage}
 \caption{On the right: cumulative luminosity versus day delivered to CMS in pp collisions, plotted for the different data-taking periods. On the left: cumulative luminosity versus day delivered by LHC (in blue) and recorded by CMS (in orange) for pp collisions from 2010 to 2018 \cite{ref37}.}
 \label{fig:IntLumi_cumulative_total}
\end{figure}

The integrated luminosities for 2017 and 2018 data-takings are displayed in the plots in Fig. \ref{fig:IntLumi1718}.

\begin{figure}[h]
 \begin{minipage}[b]{7.5cm}
   \centering
   \includegraphics[width=7.6cm]{IntLumi2017}
 \end{minipage}
% \ \hspace{1mm} \hspace{1mm} \
 \begin{minipage}[b]{7.5cm}
  \centering
   \includegraphics[width=7.6cm]{IntLumi2018}
 \end{minipage}
\caption{Integrated luminosity delivered by LHC (in blue) and recorded by CMS (in yellow) for pp collisions of 2017 (on the left) and 2018 (on the right) \cite{ref37}.}
\label{fig:IntLumi1718} 
\end{figure}
\newpage
When two bunches of protons collide, several independent proton-proton interactions can take place, from which particles can originate.
The average number of interactions depends on the beam parameters, e.g. the number of particles in a bunch, how much the bunch is focused, etc.
In 2017 there were, on average, 32 interactions per bunch crossing, as shown in Fig. \ref{fig:pileup2017}.\\ 
The presence of many primary vertices per bunch crossing is a challenge for the event reconstruction, since the particles originating from different primary vertices can be superimposed in the detector. Interactions besides the interaction of interest, that one wants to study, are referred to as \emph{pileup}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{pileup2017}
	\caption{Pile-up distribution for 2017 pp collisions.}
	\label{fig:pileup2017}
\end{figure}

\section{The CMS experiment}
The CMS experiment is a multipurpose experiment \cite{ref33}: it is designed to be able to fulfill a large variety of physics goals, ranging from the investigation of the physics underlying the electro-weak symmetry breaking, that has led to the discovery of the Higgs boson in 2012 \cite{ref2} \cite{ref3}, to the exploration of new physics, probing the predictions from BSM theories. \\
The CMS community is very numerous and spread all around the world: it involves more than  4000 scientists in 51 countries.

\subsection{The coordinate system}
The CMS coordinate system is right-handed and its origin is at the centre of the detector, which is the nominal interaction point (IP). The $x$-axis points radially inward to the center of the LHC ring, the $y$-axis points vertically upward and the $z$-axis points horizontally along the counter clockwise beam direction. Since the experiment has a cylindrical symmetry, it is very useful to define cylindrical coordinates to label the position of particles. In particular, a radial coordinate $r$ and two angles are used.
The $r$ coordinate  is measured in the $x-y$ plane, the azimuthal angle $\phi$ is defined as the angle measured from the $x$-axis in the $x-y$ plane and the polar angle $\theta$ is measured from the $z$-axis, in the same plane.\\
However, very often, instead of the polar angle, the pseudorapidity $\eta$ is used, which is defined by the equation \ref{eq:eta}.

\begin{equation}
\mathrm{\eta = - ln\ \bigg( tan\ \frac{\theta}{2} \bigg)}
	\label{eq:eta}
\end{equation}

Therefore, the pseudorapidity is null in the $x-y$ plane and infinity for a direction parallel to the beamline. This quantity is preferred over the polar angle because the particle production is constant as a function of $\eta$ and it is Lorentz invariant under boosts along the longitudinal axis.\\
Based on pseudorapidity values, the CMS detector can be divided in: 
\begin{itemize}
	\item the \emph{barrel}, corresponding to the region with $|\eta| <$ 1.2
	\item two \emph{endcaps}, characterized by 1.2 $< |\eta| <$ 2.4
\end{itemize}
%The CMS geometric acceptance is therefore limited to the region of $|\eta|<$2.4. \\
The energy and momentum measured for $\eta$ = 0 , i.e. transverse to the $z$-axis, are denoted as $\mathrm{E_{T}}$ and $\mathrm{p_{T}}$ and they are defined respectively by: $\mathrm{E_{T} = E\ sin\ \theta}$ and $\mathrm{p_{T} = p\ sin\ \theta}$. \\
Distances in $\phi$ and $\eta$ are denoted $\Delta \phi$ and $\Delta \eta$ and they are used to define cones around an axis with a border given by $\Delta R$, computed as shown in eq. \ref{eq:DeltaR}.

\begin{equation}
\mathrm{\Delta R = \sqrt{(\Delta \phi)^{2} + (\Delta \eta)^{2}}}
	\label{eq:DeltaR}
\end{equation}

In the following, before describing in detail the CMS subdetectors (indicated in Fig. \ref{fig:CMSdet}) going from the inner one in the barrel, to the most external in the endcaps, I will briefly illustrate the characteristics of the CMS magnet, which has a fundamental role in the measurement of the momentum and charge of particles.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.14]{CMSdet}
	\caption{Overview of the whole CMS detector with the different subdetectors.}
	\label{fig:CMSdet}
\end{figure}

\subsection{Magnet}
The momenta of charged particles and the sign of their electric charge are determined by the curvature of the particle trajectory in a magnetic field.
To fulfill the required performance of the muon system, in order to be able to determine the sign of muons with very high momentum, up to the order of TeV, CMS chose a very strong magnetic field within a compact volume.
The CMS large superconducting solenoid, made of niobium titanium and cooled down to $\sim$4.5 K with liquid helium, is 12.5 m long and has an inner diameter of 5.9 m \cite{ref44}.
It produces a uniform field in the axial direction and therefore the particles trajectories are bended in the transverse ($x-y$) plane. In the volume of the inner tracker and calorimeters the field is about $\sim$ 3.8 T, generated by a circulating current of 18 kA.
The return flux is steered by an external iron yoke with three layers, and between them the muon system is installed. In the latter region the magnetic field is about 2 T \cite{ref38}.

\subsection{Inner tracker}
The inner tracking system measures the trajectories of charged particles in the pseudorapidity region: $\eta < |2.5|$. It is therefore the closest subdetector to the interaction point and it operates in the region characterized by the highest flux of particles.\\
For these reasons, it is required a technology able to provide very high granularity information and to guarantee good radiation hardness, while keeping to the minimum the amount of material, in order to limit multiple coulomb scattering, bremsstrahlung and nuclear interactions.
In order to fulfill all of these requirements, the silicon technology has been chosen for the whole tracker \cite{ref39} \cite{ref40}, which is made up of different detectors, as shown in Fig. \ref{fig:InnerTracker}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.37]{InnerTracker}
	\caption{Schematic view of half of the inner tracking system, showing the five different kinds of silicon detectors used \cite{ref62}.}
	\label{fig:InnerTracker}
\end{figure}

In the inner region there is a \textbf{pixel detector}, with 3 layers in the barrel and 2 in the endcaps, having pixel cells of $\approx$ 100$\times$150 $\mu m^{2}$ size. It guarantees a spatial resolution of 10 $\mu m$ in the $r-\phi$ direction $r$ and 20 $\mu m$ in the $z$ direction. Thus, it allows very precise measurements and provides a small impact parameter resolution, that is crucial for good secondary vertex reconstruction \cite{ref41}.\\
The external part of the tracker is made up of different kind of microstrip detectors, consisting of a total of 9.3 million strips, covering an active area of about 198 $m^{2}$ \cite{ref62}. \\
In the barrel there are cylindrical layers of detectors, divided into:
\begin{itemize}
	\item \textbf{Tracker Inner Barrel (TIB)},  made up of 4 layers, which provide a single-point resolution of 13-38 $\mu m$  in the $r-\phi$ direction and 23 $\mu m$ in the $z$ direction, 
	\item \textbf{Tracker Outer Barrel (TOB)}, made up of 6 layers, providing a resolution of 18-47 $\mu m$ in the $r-\phi$ direction and 47 $\mu m$ in $z$.
\end{itemize}
In each endcap there are 12 disks, containing  concentric rings of silicon strip modules, divided among:
\begin{itemize}
	\item \textbf{Tracker Inner Disks (TID)}, composed of 3 disks, providing the same resolution as TIB detectors,
	\item \textbf{Tracker EndCaps (TEC)}, composed of 9 disks, providing the same resolution as TOB detectors.
\end{itemize}

Fig. \ref{fig:Tracker_MaterialBudget} shows the material budget of the CMS tracker in units of radiation lengths as a function of $\eta$, as estimated from simulation (with an accuracy better than 10 \%).
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.43]{Tracker_MaterialBudget}
	\caption{Total thickness $t$ of the tracker material traversed by a particle produced at the IP, expressed in units of radiation length $X_{0}$. The contribution to the total material budget of each of the subsystems that comprise the CMS tracker is shown, together with contributions from the beam pipe and from the support tube that surrounds the tracker \cite{ref62}.}
	\label{fig:Tracker_MaterialBudget}
\end{figure}

\subsection{Calorimeters}
\subsubsection*{Electromagnetic Calorimeter}
The CMS electromagnetic calorimeter (ECAL) is a homogeneous calorimeter made of Lead Tungstate ($PbWO_{4}$) scintillating crystals, characterized by a scintillation decay time comparable with the 25 ns time interval between two consecutive bunch crossings.
Moreover, this material is characterized by a small Moliere radius (21.9 mm) and a short radiation length (8.9 mm), that allow good shower containment in a limited space \cite{ref42}.
Crystals have a trapezoidal shape and a length of 230-220 mm, corresponding to 25.8 and 24.7 radiation lengths respectively. The scintillation light is collected by silicon Avalanche Photo-Diodes (APDs) or Vacuum Photo-Triodes (VPTs).\\
The layout of CMS ECAL is shown in Fig. \ref{fig:ECAL}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.27]{ECAL}
	\caption{Layout of the CMS electromagnetic calorimeter, showing the $\eta$ coverage of the different calorimeter regions.}
	\label{fig:ECAL}
\end{figure}

It has a total coverage of $|\eta| <$ 3 and is divided into:
\begin{itemize}
	\item a \textbf{ECAL Barrel (EB)} covering the region 0 $< |\eta| <$ 1.479 and equipped with APDs,
	\item two \textbf{ECAL Endcaps (EE)} in the region 1.479 $< |\eta| <$  3.0, equipped with VPTs.
	\item a \textbf{Preshower (ES)} in front of each endcap in the region with 1.653 $< |\eta| <$ 2.6.
\end{itemize}
The preshower detectors consist of a sampling calorimeter per endcap, made up of two layers of lead radiators to initiate electromagnetic showers from incoming electrons and photons, followed by silicon strip detectors to measure the energy deposit and the transverse shower profile. 
This preshower system is fundamental to identify and reject the $\pi_{0}$ mesons decaying into two photons and to improve the measurement of the position of electrons and photons, because it has a higher granularity than the EE.

\subsubsection*{Hadronic Calorimeter}
The CMS hadronic calorimeter (HCAL) is a sampling calorimeter, using Brass as absorber material, plastic scintillator tiles as active medium (sandwiched between the absorbers), Wavelength Shifting fibers (WLS) to modify the frequency of the scintillation light and optical fibers to transfer the light to the detectors which are hybrid photodiodes. 
Brass was chosen for its short interaction length and because it is a non-magnetic material \cite{ref43}.\\
The HCAL is divided in two parts:
\begin{itemize}
	\item a \textbf{HCAL Barrel (HB)} covering the region: $|\eta| <$ 1.4 , 
	\item two \textbf{HCAL Endcaps (HE)} in the region 1.3 $< |\eta| <$ 3.0.
\end{itemize}
Since the absorber depth of the ECAL Barrel and the HCAL Barrel in the solenoid is not enough to contain the whole particle shower, an additional calorimeter, \textbf{HCAL Outer (HO)}, is placed as a tail catcher, external with respect to the cryostat and within the return yoke, using the iron as absorber. The shower containment and therefore the energy resolution of the calorimeter are thus improved.\\
The location of HCAL and ECAL detectors with respect to the CMS magnet is shown in Fig. \ref{fig:HCAL}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{HCAL}
	\caption{Location of the different calorimeters with respect to the CMS magnet.}
	\label{fig:HCAL}
\end{figure}

In order to improve the identification of forward jets, which is very important for the rejection of many backgrounds, HB and HE are complemented by a very \textbf{Forward calorimeter (HF)}, that extends the pseudorapidity coverage from $|\eta| <$ 3.0 up to $|\eta| <$ 5.2 (not shown in Fig. \ref{fig:HCAL}.
It uses a Cherenkov-based, radiation-hard technology (because the particle flux in this very forward region is extremely high) with steel as absorber material and quartz fibres as active medium.
Cherenkov light, emitted by particles in the quartz fibres, is channelled to photomultipliers.
Neutral components of the hadron showers are preferentially sampled in the HF, leading to narrower and shorter hadronic showers.
Moreover, the fibres inside HF are arranged in such a way is possible to distinguish showers generated by electrons and photons, which deposit a large fraction of their energy in the first 22 cm of the calorimeter, from those generated by hadrons, which produce, on average, nearly equal signals in both calorimeter segments (respectively long 22 and 143 cm).

\subsection{Muon system}
The main tasks of the CMS muon system are the muon identification and the precise measurement of $\mathrm{p_{T}}$ and charge of muons with energies ranging from few GeV up to few TeV. Additionally, it provides a robust trigger for events that involve muons and a precise time measurement of the bunch crossing \cite{ref45} .
The system is placed outside the magnet and the detector stations are integrated into the iron return yokes so that the 3.8 T magnetic field, inside the solenoid, and the 1.8 T average return field, bend the muon tracks in the transverse plane, thus allowing the measurement of their $\mathrm{p_{T}}$. 
Furthermore, because of the large amount of material in front of the muon chambers, also due to the presence of the magnet, the muon system is well shielded from charged particles other than muons, making their identification easier \cite{ref46} \cite{ref47}. \\
The \emph{R-z} cross section of a quadrant of the CMS muon spectrometer  is shown in Fig. \ref{fig:MuSystemOld}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{MuSystemOld}
	\caption{A quadrant of CMS muon system with the axis parallel to the beam ($z$) running horizontally and the radius ($R$) increasing upward. The three different subdetectors are highlighted: Drift Tubes (in yellow) are installed in the Muon Barrel (MB), Cathode Strip Chambers (in green) are placed in the Muon Endcap (ME) and Resistive Plate Chambers (in blue) are present in both, barrel and encaps (and labelled as RB and RE). The dark grey areas are the steel flux-return disks of the magnet.}
	\label{fig:MuSystemOld}
\end{figure}

The muon system is made up of three different kinds of gaseous detectors, which assure the robustness and redundancy of the system. \\
These detectors are: 
\begin{itemize}
	\item \textbf{Drift Tubes (DT)} in the barrel, for $|\eta| <$ 1.2,
	\item \textbf{Cathode Strip Chambers (CSC)} in the endcaps, with 0.9 $< |\eta| <$ 2.4,
	\item \textbf{Resistive Plate Chambers (RPC)} in the barrel and in the endcaps, in the region with 0.9 $< |\eta| <$ 1.6.
\end{itemize}
Owing to the specific characteristic of each type of these detectors, they are installed in different regions of the experiment, characterized by different flux and magnetic field values. \\
In particular, the DT are used only in the barrel region, where the residual magnetic field and the muon and neutron induced background rate are low, because they don't have a high rate capability and the magnetic field should modify as less as possible the trajectory of the particles inside them in order to obtain good resolutions. \\
In the endcaps, on the contrary, there is a higher residual magnetic field and large particle rate, and CSC have been installed there because they are most suitable for these radiation conditions and they can work without any problem inside the magnetic field.
Both DT and CSC provide a very good spatial resolution for the measurement of the $p_{T}$ of charged particles. 
In addition to them, RPC are placed in both regions (barrel and endcaps), in order to guarantee the redundancy of the system. Owing to their very good timing, these detectors mainly contribute to the trigger.\\
Moreover, DT, CSC and RPC have different sensitivity to the backgrounds, assuring the robustness of the system. In this region the background is composed mainly by secondary muons produced in $\pi$ and K decays, or coming from punch-through hadrons (due to hadron shower remnants penetrating through the calorimeters and reaching the muon system) and from low energy electrons originating after slow neutron capture by nuclei, with subsequent photon emission.

\subsubsection*{Drift Tubes}
The Muon Barrel system of detectors (MB) is made up of 4 stations, arranged in coaxial cylinders around the beamline and interleaved with the iron yoke. It is also divided into five wheels along the beam direction following the five wheels of the return yokes.\\ 
In this region there are in total 250 drift chambers.\\
The basic element of a DT chamber is the drift cell, shown in Fig. \ref{fig:DT}.
It is a tube with a rectangular cross section, filled with an Ar/CO$_{2}$ mixture (85/15) and operating at a gas gain of $10^5$. 
The cathodes stripes are placed along the shorter sides of the rectangle, while the anode wire is in the middle of the cell. A charged particle passing through the detector, ionizes the gas and the produced electros drift towards the anode wire. Since the drift velocity in the operating conditions is known and constant (because the geometry of the cell guarantees a uniform electric field), from the measurement of the electrons drift time is possible to obtain the position of the ionizing  particle.\\
A single drift cell has a cross-section of 42$\times$13 mm$^{2}$ and wire length 2-3 m. It is characterized by a maximum drift time of $\sim$ 400 ns and a single point resolution of $\sim$200 $\mu m$.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{DT}
	\caption{Section of a drift cell of a Drift Tube detector, showing the anode wire and the cathode strips, as well as the drift lines and the isochrones \cite{ref69}. }
	\label{fig:DT}
\end{figure}

Each DT is composed of 2 or 3 superlayers (SL), each made of 4 stacked layers of drift cells. The orientation of the anode wires is different among the SL, in order to provide information regarding different coordinates. In the outer SL the wires are parallel to the beamline, while in the inner one they are orthogonal to the beamline. The former allows a track measurement in the plane ($r-\phi$), in which the low residual magnetic field bends the tracks, while the latter measures the $z$ coordinate.

\subsubsection*{Cathode Strip Chambers}
The tracking measurement of muons in the two endcaps is the main task of the Cathode Strip Chambers (CSC), which are arranged in the Muon Endcap (ME) system in 4 stations.\\
The CSC is a multi-wire proportional chamber, in which the cathode plane is segmented into strips perpendicular to the wire direction. These chambers are operated at a gain of 7 $\times 10^4$, using a gas mixture of $\mathrm{Ar/CO_{2}/CF_{4}}$ (40/50/10). Each chamber has a trapezoidal shape and is made of 7 cathode planes stacked together, forming 6 gas gaps $\sim$ 10 mm thick, each containing a plane of anode wires, as displayed in Fig. \ref{fig:CSC1}.\\ 
In Fig \ref{fig:CSC2} is illustrated the mechanism of formation on the signal: when a muon passes through the chamber, it produces an avalanche in the gas, inducing signals both on the wires and on the cathode strips.
These two contributions are combined in order to obtain the position of the ionizing particle, since the wires give information on the radial coordinate, while the cathode planes are segmented into radial strips, orthogonal to the wires.\\
The resulting spatial resolution depends on the CSC station in consideration, but on average is about 80 $\mu m$.

\begin{figure}[h]
 \begin{minipage}[b]{5cm}
   \centering
   \includegraphics[width=5cm]{CSC1}
   \caption{Layout of a CSC showing the 7 trapezoidal layers which form 6 gas gaps with planes of anode wires.}
   \label{fig:CSC1}
 \end{minipage}
\ \hspace{2mm} \hspace{2mm} \
 \begin{minipage}[b]{8.5cm}
  \centering
   \includegraphics[width=8cm]{CSC2}
   \caption{On the top: view of the cross section a gas gap with the anode wires, the cathode plane and of a muon passing through. On the bottom: Scheme of the formation of the signal in the detector due to the avalanche reaching the wire and the induced charge distribution on the cathode strips \cite{ref69}.}
   \label{fig:CSC2}
 \end{minipage}
\end{figure}

\subsubsection*{Resistive Plate Chambers}
The main goal of the 1056 RPC, installed both in the barrel and in the endcaps of CMS, is to provide a fast trigger signal, while adding, at the same time, redundancy to the muon spectrometer.The RPC are gaseous parallel-plate detectors characterized by an excellent time resolution (from 1 ns to 50 ps) and therefore able to provide a precise bunch crossing identification.\\
A single RPC consist of two parallel planes made of bakelite (a very resistive resin), externally coated with graphite and separated by a 2 mm wide gas gap, filled with a gas mixture of 96.2\% $\mathrm{C_{2}H_{2}F_{4}}$ (freon) + 3.5\% $\mathrm{iC{4}H_{10}}$ (isobutane) + 0.3\% $\mathrm{SF_{6}}$ + water vapour.\\
In CMS two RPC are combined in order to improve their efficiency of detection and the signals produced by the avalanches generated by the ionization of the gas in the passage of a charge particle, are collected on a set of readout aluminum strips, placed between the two chambers, as shown in Fig. \ref{fig:RPC}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{RPC}
	\caption{Schematic view of a dual RPC CMS detector.}
	\label{fig:RPC}
\end{figure}

RPC can operate in two different modes: a \emph{streamer} mode with a strong electric field that produces localized gas discharges in the region near the passage of the ionizing particle, or an \emph{avalanche} mode, in which the electric field is less strong than the previous one. The former mode allows only few counts per unit area, while the latter one, because of the reduced charge generated in the ionization, is characterized by an increased counting capacity of the chamber. \\
For this reason in CMS the RPC operate in avalanche mode, allowing the detectors to sustain higher rates. 

\subsection{CMS trigger system}
In CMS $\sim 10^{9}$ interactions take place per second, but data can be written to permanent storage with a maximum rate of 600 Hz. Moreover, the cross section of interesting physics phenomena is very low, making useless to store all the data.
For these reasons a trigger system, able to select only the potential interesting events, has a fundamental importance for the experiment.
The decision to retain or to discard an event has to be taken in less than 25 ns, the time interval between two collisions, which is too small to retrieve data from all the detectors. 
Therefore, CMS uses a multi-level trigger system \cite{ref48} \cite{ref49}, divided into:
\begin{itemize}
	\item \textbf{Level 1 trigger (L1)}: at this level the decision is taken using the raw data coming from the calorimeters and muon detectors, which are the fastest ones. Only  $10^{5}$ events per second are passed to the next level of trigger.
%	all the data is stored in the pipelined memory buffers for a maximum of 3.2 $\mu s$, which corresponds to the maximum latency time (i.e. the time needed to transfer the raw data from the detector to the electronics that takes the L1 decision and back + the time needed to take the decision ($\sim$1 $\mu s$)).
 	\item \textbf{High Level Trigger (HLT}): at this level the decision is taken by a farm with several thousand of processors that reconstruct the data. The rate of passing events is further reduced to few hundreds of Hz, before they are stored permanently.
\end{itemize}

\subsubsection*{L1 trigger}
The first level trigger is provided by custom programmable electronics (e.g. FPGA) that combines the information coming from the fastest CMS detectors in order to decide whether to store or to discard an event.\\ 
All the data are temporarily stored in pipelined memory buffers inside the electronics of each subdetector for 3.2 $\mu$s. This is the sum of the time needed to take the decision ($<$ 1 $\mu$s) and the time needed to transfer the data from subdetectors to where the decision is taken and back. Then, if the event is considered interesting, it is moved to a buffer to be stored while waiting to be processed by the HLT. \\
The L1 uses the Muon trigger and the Calorimeter trigger, which identify “trigger objects”  as electrons, photons, jets and muons, and categorize them based on their quality (determined by energy or momentum values). The information provided by these two triggers are then combined by the \emph{Global Trigger}, that takes the final decision. The Muon trigger uses the segments coming from DT and CSC and the single hits from the RPC.\\
A complete overview of the CMS L1 trigger is shown in Fig. \ref{fig:L1}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{L1}
	\caption{An overview of the CMS L1 trigger. Data from the calorimeters (HF, HCAL, ECAL) are processed first regionally in a \emph{Regional Calorimeter Trigger} (RCT) and then globally in a \emph{Global Calorimeter Trigger} (GCT). The hits in the muon system (RPC, CSC, DT) are processed either via a pattern comparator or via a system of segment and track-finders and sent to a global muon trigger (GMT). The information from the GCT and GMT is combined in a global trigger (GT), which makes the final trigger decision. This decision is sent to the tracker (TRK), ECAL, HCAL or muon systems (MU) via the trigger, timing and control (TTC) system. The data acquisition system (DAQ) reads data from various subsystems for offline storage.}
	\label{fig:L1}
\end{figure}
\newline Inner tracker data are not used in L1 because of the large number of channels that %allows its very high resolution: it 
would require too much time to read them out.\\
The simplest L1 triggers are in general those based on the presence of one object with a $\mathrm{p_{T}}$ above a predefined threshold (\emph{single-object triggers}) and those based on the presence of two objects of the same type (\emph{di-object triggers}) with either symmetric or asymmetric thresholds. 

\subsubsection*{High Level Trigger}
The entire decision process at this level takes $\sim$100 ms: each processor of the farm works on the reconstruction of one event at a time, using data with full resolution and granularity, eventually from all the subdetectors. There are few hundreds of different HLT paths, that look for the presence of particular objects and signatures in an event. 
In order to minimize the decision time, the selection is made in a sequence of nested logical steps: initially only some parts of the event, the less expensive in computational terms, are reconstructed (e.g. the deposit energy in the ECAL) and a filter is applied in order to decide if the reconstructed objects pass the trigger thresholds. If this is the case, the reconstruction continues with the successive step, otherwise the execution of the path is stopped.

\section{The World LHC Computing Grid}
Events that have fired the HLT are stored and then reprocessed in order to be analysed.
In order to deal with the very demanding requirements that storing, processing and analysing the huge amount of data produced at LHC experiments poses, an infrastructures worldwide distributed, called “World LHC Computing Grid” (WLCG) has been created \cite{ref50}.
It is made up of 170 computer centres distributed in 42 countries, with a total of $\sim$1 million of computer cores and 1 exabyte of storage.
The different centres are connected via high-speed networks, as shown in Fig. \ref{fig:WLCG}. These centres are organized in different levels, called \emph{Tiers}, based on the number of computer and the performance they can provide.
For this reason, tiers belonging to different levels have different tasks.

The fundamental centre is the \emph{Tier 0} located at CERN. 
Its task is to collect all the raw data from the LHC experiments and to organise it in different groups (\emph{Primary Datasets}) according to the trigger path with which they were acquired.  Moreover, it convert the raw data into data formats useful for analysis: RECO and AOD (Analysis Object Data). \\
The converted data are transferred and shared among \emph{Tier 1} centres (13 around the world), where they are reconstructed. \\
\emph{Tier 2} centres are instead used for single physics analysis. \\
In particular, the Tier 2 present in Bari, \emph{ReCaS}, has been extensively used for the analysis described in this thesis.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.4]{WLCG}
	\caption{Schematic representation of the WLCG distributed infrastructure. It is organized in different levels, called \emph{Tiers}, connected via high-speed networks.}
	\label{fig:WLCG}
\end{figure}

%\section{LHC and CMS upgrades}
%
%The schedule of the upgrades of LHC is shown in Fig. \ref{fig:LHC_upgrade}.
%
%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.28]{LHC_upgrade}
%	\caption{LHC upgrade schedule bla bla.}
%	\label{fig:LHC_upgrade}
%\end{figure}


\chapter{Events reconstruction in CMS}
The reconstruction of an event produced in the collision of particles consists in combining together all the information coming from the different detectors, in order to obtain the trajectory of the particles produced in the collision, to identify them (photon, electron, muon, charged hadron, neutral hadron) and to measure their characteristic quantities (momentum, energy, etc).\\
Each kind of particle leaves in the different subdetectors a particular signature, as shown in Fig. \ref{fig:CMS_slice}, which makes the particle identification possible. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.2]{CMS_slice}
	\caption{Different signatures of particle in CMS detectors. The trajectory of the particles that interact with the tracker are drawn in full line: electrons in red, muons in light blue and charged hadrons in green. The traectories of neutral particles, that interact only with the calorimeters, are indicated with dashed lines: neutral hadrons in green and photons in blue. The muon and the charged pion are positively charged, and the electron is negatively charged \cite{ref60}.}
	\label{fig:CMS_slice}
\end{figure}
\newline For example, photons are detected from ECAL energy clusters that don't correspond to any signal in the tracker, while electrons leave a clear signal in the tracker with linked ECAL energy clusters, or possible bremsstrahlung photons emitted along the way through the tracker material.
Muons, on the other hand, are clearly identified as a signal in the tracker consistent with a track or some hits in the muon system. 
Neutral hadrons are identified as HCAL energy clusters not linked to any charged hadron trajectory.\\
If during the passage through the active material of the detectors the particle interacts, a signal is produced and is recorded as a point in space, called \emph{recHit}. All the recHits are then connected together, in diferent possible ways, to reconstruct the particle trajectory.

\section{Particle Flow algorithm}
The Particle Flow algorithm \cite{ref60} correlates the basic elements from all the detectors layers (tracks and clusters) to identify each final-state particle, and combines the corresponding measurements to reconstruct the particle properties on the basis of the previous identification. This leads to a significantly improved event description.
Additionally, from all these information, the \emph{Missing Transverse Energy} (MET) can be determined. It represents the transverse momentum which escapes detection, leaving an imbalance in the transverse plane and it is defined as the negative vectorial sum of the transverse momenta of all the identified particles and reconstructed jets in the event: $E_{\ T}^{\ miss} = - \sum_{i} p_{T}^{i}$  \cite{ref61}.\\

A given particle is, in general, expected to give rise to several \emph{PF elements} in the various CMS subdetectors. The reconstruction of a particle therefore first proceeds with a \emph{link algorithm} that connects the PF elements from different subdetectors.
The pairs of elements considered by the link procedure are restricted to the nearest neighbours in the transverse plane.
This linking procedure produces \emph{PF blocks} of elements associated either by a direct link or by an indirect link through common elements.\\
In each PF block, the identification and reconstruction sequence proceeds in the following order:
\begin{enumerate}
	\item muons,
	\item electrons and bremsstrahlung photons,
	\item charged hadrons, neutral hadrons and other photons.
\end{enumerate}
As the different particles, at each step, are identified and reconstructed, the elements present among the blocks, associated to these particles, are removed from the collection.\\
The muons candidates are the first to be identified and reconstructed, and then all the elements associated to them are removed from the block.
The second kind of particles to be identified and reconstructed are the electrons and bremsstrahlung photons (i.e. energetic and isolated photons, converted or unconverted ).
Then, the last step consists of a cross identification of the remaining elements, which can belong to charged hadrons, neutral hadrons or photons. Usually hadrons produce secondary particles by interacting in the tracker material via nuclear reactions.\\
When all the blocks have been processed and all the particles have been identified, the reconstructed event is revisited by a post-processing step.

\section{Tracks and Primary Vertex reconstruction}

\subsection{Tracking of charged particles }
\label{Track charged particles}
The main goal of the reconstruction of the tracks of charged particles is the evaluation of their momentum. This is possible by considering the bending of their trajectories in the magnetic field, due to the Lorentz force. \\
Knowing the value of the magnetic field in each point of the space, the particle momentum in a point is estimated by evaluating the tangent to the trajectory in that point (which is a velocity) and then multiplying it by the mass of the particle and its Lorentz factor $\gamma$: $p = m\ \gamma\ v$

However, there are some factors that makes the estimate more complicate and that have to be taken into account because they modify the momentum of the particles:
\begin{itemize}
	\item inhomogeneity of the magnetic field,
	\item energy loss in the detectors,
	\item multiple coulomb scattering. %that modifies the trajectory (check!)
\end{itemize}
The energy loss in the detectors can be evaluated through the Bethe-Bloch formula, that describes the mean rate of energy loss due to the ionization of the atoms of the material. 
For what concerns the last contribution, instead, if the particle crosses a sufficient thickness of material, the distribution of the values of the deflection angle is a Gaussian centered at zero.
%[ eq. Bethe Bloch and plot ? ]

\subsubsection*{From RecHits to tracks: how to connect the dots}
After that the local reconstruction of the RecHits collected by the silicon detectors of the tracker (with the estimation, for each detector layer, of the particle positions and uncertainties) is carried out, 
the procedure to obtain tracks from the RecHits is independent of the type of silicon subdetector and is characterized by some precise logical steps:
\begin{enumerate}
	\item Seed generation
	\item Track finding 
	\item Track fitting
	\item Track selection
\end{enumerate}
The passage from the RecHits to tracks is performed by using the CMS tracking software, referred to as \emph{Combinatorial Track Finder} (CTF) \cite{ref62}.
It allows pattern recognition and track fitting to occur in the same framework \cite{ref64}.  \\
The reconstruction goes on in an iterative way, with the aim to reduce and simplify the combinatorial complexity arising from the large number of hits.
The initial iterations of the CTF search for tracks that are easiest to recognize (e.g. the ones which large $\mathrm{p_{T}}$, which are quite isolated) and after each iteration, hits associated with tracks are removed, simplifying the search for more difficult classes of tracks (e.g. low $\mathrm{p_{T}}$ tracks).\\
In the following, the four steps through which each iteration proceeds are explained in more detail.

\subsubsection{Seed generation}
Seed generation provides initial track candidates for a preliminary estimation of the trajectory, its parameters and its uncertainties. 
Inside the tracker the magnetic field is almost uniform, therefore the trajectories of charged particles are helicoidal and require five parameters to be uniquely defined. These are: the 3 position coordinates, the angle that the tangent to the trajectories makes with respect to the detector and the ratio between the electric charge and the momentum of the particle. \\
In order to extract these parameters, three 3D hits or two 3D hits plus 1 constraint (e.g. a constraint on the trajectory origin: the hypothesis that the particle originated close to the beam spot) are needed.\\
Seeds are constructed in the inner part of the tracker and the track candidate is built outwards. 

\subsubsection*{Track finding}
The estimation of the values of the five parameters needed to define the trajectory is performed using linear fitting algorithms, like the “Kalman filter” (KF) \cite{ref66} \cite{ref63}.
This filter acts iteratively, taking as starting parameters the coarse ones provided by the trajectory seed and updating them by adding hits from successive detector layers, to build track candidates \cite{ref65}. 
In particular, firstly are determined the layers which are compatible with the initial seed trajectory and then the trajectory is extrapolated to these layers, according to the equation of motion of a charged particle in a constant magnetic field, but taking into account also the multiple coulomb scattering and energy loss in the material.\\
The five track candidates with the best normalized $\chi^2$ found at each layer are then propagated to the next compatible layers, until the outermost layer is reached or a terminating condition is satisfied.\\
At the end of this stage, to each trajectory is associated a collection of hits and an estimate of the track parameters.

\subsubsection*{Track fitting}
The full information about the trajectory is only available when all hits are known, and the estimate can be biased by constraints applied during the seeding stage. 
For this reason, the trajectory is refitted using the KF, which is initialized with the parameters coming from a preliminary fit of the innermost hits of the track.
Then the fit goes on iteratively, from the inside outwards, through all of the hits, and the track trajectory and the estimated hit position uncertainty, are updated after the progressive addition of  new hits.

\subsubsection*{Track selection}
The previous reconstruction step produces several “fake tracks” , id est tracks not associated with a simulated particle. A reconstructed particle is associated with a simulated track if at least 75\% of the hits assigned to the reconstructed track originate from the simulated particle. 
To avoid fake tracks, if the tracks have a good $\chi^2$, the selection is based on:
\begin{itemize}
	\item number of layers that have hits. The fraction of fake tracks decreases exponentially with the increasing if this quantity.
	\item compatibility with a primary interaction vertex.
\end{itemize}
Depending on the requirements that the tracks fulfill, they can be classified as  \emph{high-purity tracks}, if they satisfy the more stringent criteria, or \emph{loose tracks}, if they fulfill only minimum requirements.\\
At the end of this step, the selected tracks are merged into a single collection.

\subsection{Tracking efficiency}
The tracking efficiency is defined as the number of matched reconstructed tracks divided by number of simulated tracks, and it is a measure of the performance of the detector.\\ 
For CMS inner tracker, the muon-tracking efficiency is measured with a tag-and-probe technique on $\mathrm{Z\rightarrow\mu^{+}\mu^{-}}$ \cite{ref116} \cite{ref69}. The values obtained are shown in Fig. \ref{fig:TrackerEff} as a function of $\mathrm{p_{T}}$ and $\eta$ of the muon and in Fig. \ref{fig:TrackerEff_Nvertices} as a function of the number of primary vertices. The data used for this measurement are those collected during the 2017 data-taking, at 13 TeV in pp collisions. \\

\begin{figure}[h!]
 \begin{minipage}[b]{7.7cm}
   \centering
   \includegraphics[width=7.7cm]{TrackerEff_pT}
 \end{minipage}
 %\ \hspace{1mm} \hspace{1mm} \
 \begin{minipage}[b]{7.7cm}
  \centering
   \includegraphics[width=7.7cm]{TrackerEff_eta}
 \end{minipage}
\caption{Muon tracking efficiency as a function of the transverse momentum (on the left) and of $\eta$ of the muon (on the right). Data (collected in 2017 at a center of energy of 13 TeV) are shown with black dots while the simulation with light blue rectangles. The uncertainties shown are statistical "-/+ 1" $\sigma$" \cite{ref62a}. These efficiencies were measured with a tag-and-probe technique on $\mathrm{Z\rightarrow\mu^{+}\mu^{-}}$ \cite{ref116} \cite{ref69}.}
\label{fig:TrackerEff} 
\end{figure}

\newpage
\begin{figure}[h!]
   \centering
   \includegraphics[width=7.7cm]{TrackerEff_Nvertices}
	\caption{Muon tracking efficiency as a function of the number of primary vertices. Data (collected in 2017 at a center of energy of 13 TeV) are shown with black dots while the simulation with light blue rectangles. The uncertainties shown are statistical "-/+ 1" $\sigma$" \cite{ref62a}. This efficiency was measured with a tag-and-probe technique on $\mathrm{Z\rightarrow\mu^{+}\mu^{-}}$ \cite{ref116} \cite{ref69}.}
	\label{fig:TrackerEff_Nvertices} 
\end{figure}


\subsection{Primary Vertex reconstruction}
Using the reconstructed tracks, it is possible to reconstruct the Primary Vertices (PV), id est the vertices of the proton-proton interactions in each event, including the ones originating from pileup collisions.\\
This reconstruction process consists of 3 steps:
\begin{enumerate}
	\item selection of the tracks that are consistent with the hypothesis of being produced promptly in a primary interaction,
	\item clustering of these tracks according to their $z$ coordinate at the point of closest approach to the centre of the beam spot,
	\item fitting of all the vertices containing at least 2 tracks, with an \emph{Adaptive Vertex Fitter} \cite{ref68}.
\end{enumerate}
The last step provides an estimate of the vertex parameters (position coordinates, number of degrees of freedom, indicators that estimate the efficiency of the fit).\\ 
The primary-vertex resolution depends strongly on the number and on the momenta of tracks used in the fit. \\
Results from a study of the primary-vertex resolution in $x$ and $z$ as a function of the number of tracks associated to the vertex, using a minimum-bias data sample at 7 TeV, are shown in Fig. \ref{fig:PV_Eff}.

\begin{figure}[h!]
   \centering
   \includegraphics[width=15cm]{PV_Eff}
	\caption{Primary-vertex resolution in $x$ (on the left) and in $z$ (on the right) as a function of the number of tracks at the fitted vertex, for minimum-bias events at 7 TeV in pp collisions \cite{ref62}.}
	\label{fig:PV_Eff} 
\end{figure}

The primary-vertex resolution results, less than 20 $\mu m$ in $x$ and 25 $\mu m$ in $z$, for primary vertices reconstructed using at least 50 tracks.

\newpage
\section{Muon reconstruction}
\label{Muon reconstruction}
A good muon reconstruction and identification is fundamental for many physics searches carried out at CMS and, in particular, it has a very important role for the analysis described in this thesis. Because of the central importance that muons have in CMS, several algorithms have been developed for their reconstruction, in order to best fulfill the specific needs of different analysis \cite{ref46}. \\
In general, muons are reconstructed using data coming from the muon system and the inner tracker. The entire muon reconstruction consists of 3 steps (the two possibilities at step 3 are alternative):
\begin{enumerate}
	\item \textbf{Local muon reconstruction}: data are reconstructed as RecHits in each muon chamber. Then in DT and in CSC the RecHits are fitted to segments.
	\item \textbf{Stand-alone muon reconstruction}: the RecHits in RPC and the segments in DT and CSC are grouped in seed and fitted to \emph{stand-alone muon} tracks, using a Kalman-filter technique.
	\item	 \begin{enumerate}
				\item \textbf{Global muon reconstruction [outside-in]}: for each stand-alone muon track a matching in the inner tracker is searched for. If a matching tracker track is found, the hits of the two tracks are combined and a global fit is performed with the Kalman filter, resulting in a \emph{global muon} track. %[ using the KF technique]
				\item \textbf{Tracker muon reconstruction [inside-out]}: tracks in the inner tracker with $\mathrm{p_{T}}>$ 0.5 GeV/c and a total momentum p $>$ 2.5 GeV/c are extrapolated to the muon system. If at least one matching muon segment (from DT or CSC) is found, the extrapolated track is referred to as a \emph{tracker muon} track. The matching between the track and the segment is done using as reference coordinate system the muon chamber one. In particular, it is required that the extrapolated track is less than 3 cm, in the $x$ coordinate, far from the corresponding muon segment.
			\end{enumerate}
\end{enumerate}
The global reconstruction, which uses stand-alone muon tracks, gives a very good momentum resolution for muons with high $\mathrm{p_{T}}$ values: $\mathrm{p_{T} \geq}$ 200 GeV.
On the other hand, the tracker reconstruction is more efficient for muons with low transverse momentum, $\mathrm{p_{T} \leq}$ 5 GeV, because it requires only one segment in the muon chambers, which is usually, for tracker muons that are not global muons, in the innermost muon station.\\
In any case, owing to the high efficiency of the tracker track and muon segment algorithms, the 99\% of the muons produced within the CMS geometrical acceptance ($|\eta|<2.4$ and having sufficiently high momentum are reconstructed either as global muon tracks or as tracker muon tracks, and very often as both \cite{ref46}.\\
When the reconstruction process is completed, global muons and tracker muons that share the same tracker track are merged into a single candidate.\\
An example of an event recorded by CMS in which four muons were reconstructed is shown in Fig.\ref{fig:4muRECO}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.22]{4muRECO}
	\caption{Longitudinal (on the left) and transverse (on the right) view of an event in CMS in which four muons were reconstructed. Three of them were identified by the DT and RPC, the fourth one by the CSC. The short black segments in the muon system show fitted muon-track segments, while the short red horizontal lines indicate the positions of RPC hits. The energy deposited in the calorimeters is indicated with red and blue bars, respectively for ECAL and HCAL \cite{ref69}.}
	\label{fig:4muRECO}
\end{figure}

\subsection{Local muon reconstruction}
The trajectory of the muon is built starting from the recHits in the sub-detectors layers (ideally one recHit per layer should be produced). At this level the reconstruction depends on the specific type of muon chamber considered.\\ In the following, the local reconstruction procedure for each kind of sub-detector of the CMS muon system will be treated in more detail.

\subsubsection*{Drift Tubes}
Inside the Drift Tubes, the footprints left by the muons passing through are 1D hits in the drift cells. From the measurement of the drift time, using time-to-digital converter (TDC) registers, it is possible to obtain only information on the distance of the particle from the anode wire, but with a left/right ambiguity. Moreover, a single hit doesn't provide any hint regarding the position of the particle along the wire.\\ 
However, since a DT chamber consists of three superlayers, each made of four staggered layers of parallel drift cells, the wires in each layer are oriented so that two of the superlayers measure the muon position in the bending plane ($r-\phi$) and one superlayer measures the position in the longitudinal plane ($r-\theta$) \cite{ref46}. 
For this reason, hits segments are reconstructed separately in the $r-\phi$ and $r-\theta$ planes and then the two projections are combined to obtain information about the third coordinate ($z$).\\
The final 3D segment has a angular resolution of $\sim$ 0.7 mrad in $\phi$ and $\sim$ 6 mrad in $\theta$.

\subsubsection*{Cathode Strip Chambers}
In Cathode Strip Chambers is possible to have information on the position of the muon by combining signals from the cathode strips (which are radial, so they measure the angle $\phi$) and from the anode wires (that are orthogonal to the strips, providing a measurement of the $r$ coordinate). 
Therefore, a 2D information is available for each layer. The data of all the layers are then combined to reconstruct a 3D line segment. \\
The position resolution of the segments varies from 50 $\mu$m to 250 $\mu$m, depending on the CSC station considered.

\subsubsection*{Resistive Plate Chambers}
In Resistive Plate Chambers the information on the position of the muon is provided by the signal induced on the readout strips, which are aligned with $\eta$. The fired adjacent strips are clustered and the exact position of the muon is estimated computing the center of gravity of the charge shared among them. This provides a resolution of $\sim$1 cm in the $\phi$ coordinate.
%[Errors are computed under the same assumption of flat probability: length of the cluster divided by $\sqrt{12}$ ]

\subsection{Stand-alone muon reconstruction}
In order to build the seeds, a pattern of segments is searched for, inside the DT (for barrel) and the CSC (for endcaps). If it is found, the $\mathrm{p_{T}}$ of the seed candidate is estimated.\\
Then, the stand-alone track reconstruction uses the KF method iteratively to extend the track, starting from the candidate seeds. 
At each iteration of the algorithm, the trajectory parameters are updated and the reconstruction is carryed out in the same way it is done for tracker tracks.  Once all the hits are fitted and the fake trajectories are removed, the remaining tracks are extrapolated to the point of closest approach to the beam line. 

\subsection{Global muon reconstruction}
The global muon reconstruction starts after the completion of the indepedent reconstruction of the stand-alone tracks and the inner tracker tracks. \\
The track matching of a stand-alone track to a tracker track consists of 2 steps:
\begin{enumerate}
	\item the definition of a region of interest (ROI) in the parameter space, that roughly corresponds to the stand-alone muon track, and the selection of the subset of the tracker tracks inside this region. The determination of the ROI is based on the stand-alone muon parameters, with the assumption that the muon originates from the interaction point. 
	\item the iteration of the previous procedure applying more stringent criteria to choose the best tracker track to be combined with the stand-alone muon. In order to do this, the stand-alone muon and the tracker tracks are propagated onto the same plane and the global track with the best $\chi^2$ is searched. If the matching fails, the reconstruction is stopped and no global track is produced.
\end{enumerate}
The final step in the reconstruction of a global muon track is the matching of it with the energy deposits in the calorimeters.

\subsection{Tracker muon reconstruction}
The tracker reconstruction consists in extrapolating the tracker tracks to the muon system, taking into account all the possible contributions from the dishomogeneity of the magnetic field, the average expected energy losses of the particle and multiple Coulomb scattering in the detector material.
If there is a suitable match between a tracker track and a stand-alone muon track, then the default global fit algorithm combines hits from the tracker and the stand-alone muon track and performs a final fit over all the hits.

\subsection{Muon Identification}
Particles which are detected as muons can be produced in CMS from various sources and therefore they can be characterized by different features \cite{ref69}.\\
In general, they can be classified into the following categories: 
\begin{itemize}
	\item \textbf{Prompt muons}: Muons produced either from decays of W, Z, and promptly produced quarkonia states, or other sources such as Drell-Yan processes or top quark production. 
	\item \textbf{Muons from heavy flavor}: Muons coming from the decay of a tau lepton or of beauty or charmed hadrons. 
	\item \textbf{Muons from light flavor}: Muons arising from the decay in flight of light hadrons (e.g. $\pi$ and K) or, less frequently, from the decay of particles produced in nuclear interactions in the detector material.
	\item \textbf{Hadron punch-through}: Particles different from muons; usually they are remnants of the hadron shower penetrating through the calorimeters and reaching the muon system.
	\item \textbf{Duplicate}: If a particle gives rise to more than one reconstructed muon candidate, the muon with the largest number of matched hits is assigned to one of the above categories, and any others are labeled as “duplicate”. They can arise either from failures of the pattern recognition of the reconstruction software, or from patterns that mimic multiple candidates.
\end{itemize}

In order to optimize the muon reconstruction requirements, to select only the muons produced in a particular kind of interaction, different identification (ID) categories have been developed and muons are assigned to them according to their characteristics.\\ Some examples of muon ID implemented in CMS are the following:
\begin{itemize}
	\item \textbf{Loose ID}: it aims to identify prompt muons originating at the PV and muons from light and heavy flavor decays. At the same time, a low rate of the misidentification of charged hadrons as muons is maintained. To belong to this category a muon has to be selected by the PF algorithm and it has to be either a tracker or a global muon.
	\item \textbf{Medium ID}: it is a category optimized for prompt muons and muons from heavy flavor decays. It contains loose muons with a tracker track that uses hits from more than the 80\% of the inner tracker layers it traverses. Moreover, the muon segment compatibility has to be greater than a certain threshold.
	\item \textbf{Tight ID}: it aims to suppress muons from decay in flight and from hadronic punch-through. A muon belonging to this category is a loose muon with a tracker track that uses hits from at least six layers of the inner tracker, including at least one pixel hit. A tight muon has to be both, a tracker and a global muon, and the tracker muon must have a segment matching in at least two muon stations, while the global fit has to satisfy precise requirements on the $\chi^2$/ndf. Finally, some conditions on the impact parameter(defined as the distance of closest approach of the muon track with respect to the beamspot) must be fulfilled, in order to select only muons compatible with the PV. 
	\item \textbf{Soft ID}: it is a category optimized for low $\mathrm{p_{T}}$ muons ($<$10 GeV). It containes tracker muons that satisfy high purity requirements and that use hits from at least six layers of the inner tracker, with at least one pixel hit. The muons belonging to this category are loosely compatible with the PV.
	\item \textbf{High $\bm{\mathrm{p_{T}}}$ ID}: it is a category optimized for muons with a high $\mathrm{p_{T}}$ ($>$ 200 GeV). These muons are both tracker and global muons and fulfill the same requirements on the impact parameters of the tight muons, but they don’t have to satisfy any requirement on the $\chi^2$/ndf of the global fit. Moreover, these muons don’t have to be selected by the PF algorithm.
\end{itemize}

In Fig. \ref{fig:MuonContribution} the distributions of $\eta$ and $\phi$ of muons belonging to a zero-biased sample of Soft muons (on the left) and Tight muons (on the right) are shown, both for data (points) and MC (histograms). The contribution from the different categories of muons to the total is highlighted with different colors.

\begin{figure}[h!]
   \centering
   \includegraphics[width=15cm]{MuonContribution}
	\caption{Distributions of kinematic variables for a zero-biased sample of muons subdivided into the different categories of contributing muons, for data (points) and for simulation (histograms). For $|\eta|$ (on the top) and $\phi$ (on the bottom) of the muons, the left plot shows the distribution for Soft Muons, and the right plot that for Tight Muons \cite{ref69}.}
	\label{fig:MuonContribution} 
\end{figure}

The pseudorapidity distribution is peaked in the forward region because there the minimum $\mathrm{p_{T}}$ required to reach the muon stations is lower than in the barrel. In fact in the endcaps the threshold is  $\mathrm{p_{T}} >$ 0.5 GeV/c, while in the barrel it is about $\mathrm{p_{T}} >$ 3–4 GeV/c.\\
The majority of reconstructed muon candidates, for both Soft and Tight muon ID, originate from decays in flight of pions and kaons. However, the Tight muons have a larger heavy-flavor component with respect to the Soft muons. \\
For both ID categories, the contribution of muons from heavy-flavor decays increases with $\mathrm{p_{T}}$. The Tight muon ID reduces the hadron punch-through contribution to 0.2\% while it is about 5\% in Soft Muons \cite{ref69}.

%\subsection{Muon Isolation}
%[ Inserirlo e/o modificarlo con la def custom di quelli della Florida]
%An important parameter used to distinguish between prompt muons and those from weak decays within jets is the so called \emph{Isolation} of the muon.
%It is quantifies the number of particles in a cone with a chosen value of $\Delta R$ (defined in eq. \ref{eq:DeltaR}), having its axis corresponding to the direction of the muon  momentum.
%In the analysis presented in this thesis a particular custom definition of the muon isolation has been developed in order to better distinguish the interesting muons from the background, based on consideration linked to the physics process of interest.
%[ def. nuova isolation ]

\subsection{Muon efficiency}
In Figg. \ref{fig:MuonEff_LooseID}, \ref{fig:MuonEff_MediumID} and \ref{fig:MuonEff_TightID} the muon efficiencies as a function of the $\mathrm{p_{T}}$ and $\eta$ of the muons, respectively selected with the Loose ID, Medium ID and Tight ID, are shown. The data used belong to the full 2017 data-taking, corresponding to an integrated luminosity of 41.3 $fb^{-1}$. These data were collected in pp collisions at a center of mass energy of 13 TeV, with single muon triggers.\\
The efficiencies are computed by means of the Tag and Probe method, exploiting the $Z\rightarrow\mu\mu$ resonance \cite{ref116}. For all the muon ID categories shown (loose, medium and tight), the number of all tracker tracks with $\mathrm{p_{T}}>$20 GeV has been used as denominator in the efficiency computation. No significant dependency with respect to the number of primary vertices was observed.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.38]{MuonEff_LooseID}
	\caption{Loose muon ID efficiency as a function of $\mathrm{p_{T}}$ and $\eta$ for 2017 data and MC \cite{ref70}.}
	\label{fig:MuonEff_LooseID}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.38]{MuonEff_MediumID}
	\caption{Medium muon ID efficiency as a function of $\mathrm{p_{T}}$ and $\eta$ for 2017 data and MC. The drops at around $\eta$ = 0.2 are due to the cracks between wheels in the muon detectors. The drops in the forward region are due to inactive chambers not modelled in the MC \cite{ref70}.}
	\label{fig:MuonEff_MediumID}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.38]{MuonEff_TightID}
	\caption{Tight muon ID efficiency as a function of $\mathrm{p_{T}}$ and $\eta$ for 2017 data and MC. The drops at around $\eta$ = 0.2 are due to the cracks between wheels in the muon detectors. The drops in the forward region are due to inactive chambers not modelled in the MC  \cite{ref70}.}
	\label{fig:MuonEff_TightID}
\end{figure}

%\begin{figure}[h]
%	\centering
%	\includegraphics[scale=0.75]{dimuons_2016}
%	\caption{The dimuon invariant mass distribution reconstructed by the CMS LHT with data  colected in 2016 data-taking at a center of mass energy of 13 TeV. The gray distribution correspond to the data collected with the inclusive double-muon trigger algorithm, while the colored ones have been collected with triggers dedicated to selecting resonances at low masses, as indicated in the legend.}
%	\label{fig:dimuons_2016}
%\end{figure}
%
%-	Plot Efficienze delle varie ID [ + eventualmente pag.71-72 Raffaella and tag and probe pag 101 Vanohffer  ] \cite{ref70}


\section{Electron reconstruction}
The signature of an electron inside CMS is given by hits in the silicon detectors of the inner tracker and clusters inside the ECAL crystals, where the electron releases all its energy. The measure of this latter energy deposit is the starting point for the electron reconstruction, which goes through the following steps:
\begin{enumerate}
	\item Energy measurement
	\item Seeding
	\item Tracking
	\item Association track–cluster
\end{enumerate}
A standalone approach is combined with the global particle-flow (PF) algorithm for a better performance \cite{ref72}. 

\subsection{Energy measurement}
Electrons interacting in the electromagnetic calorimeter deposit almost all their energy inside its crystals. However, due to the presence of the material in front of the ECAL, it can happen that electrons radiate photons and lose part of their energy via bremsstrahlung. It will result in an energy deposit which is more contained and less spread over the calorimeter crystals.
It is estimated that the electron energy lost before reaching the ECAL is on average 33\% - 86\%, going from $\eta \approx$0 to $|\eta| \approx $1.4.
Therefore, estimating properly the value of this loss is of crucial importance in electrons reconstruction \cite{ref71, ref73}. 
The photons radiated via bremsstrahlung are mainly spread in the $\phi$ direction (the spread in $\eta$ direction is usually negligible, except for electrons with $\mathrm{p_{T}}<$ 5 GeV) because of the bending of the electron trajectory due to the magnetic field.\\
In order to measure the energy of the radiated photons, two clustering algorithms have been developed: the \emph{hybrid algorithm}, in the barrel, and the \emph{multi-5$\times$5}, in the endcap.

The first algorithm, used in the ECAL barrel (EB), considers arrays of 5$\times$1 crystals in $\eta$-$\phi$ around the \emph{seed crystal}, which is a crystal characterized by an excess in energy deposit with respect to the other neighbours. If the total energy deposited in this group of crystals is greater than 0.1 GeV, they are grouped with the contiguous array of crystals, forming a cluster. The final global cluster, called \emph{SuperCluster} (SC), must contain a seed array with energy greater than a certain threshold.

The second algorithm, used in the ECAL endcaps (EE) and in the preshower (PS), is similar to the first one but considers a 5$\times$5 matrix around a seed crystal, whose energy has to exceed 1 GeV in order to be added to the SC.
Finally, the SC energy and position are measured: the former is given by the sum of all the energies of its clusters, while the second is calculated as the energy-weighted mean of the cluster positions. 
 
%On the other hand, being part of the particle flow reconstruction, there exist also another algorithm with the aim of reconstructing the particle showers individually.

\subsection{Seeding}
As seen in \ref{Track charged particles}, the tracks of charged particles inside the tracker can be reconstructed using the KF. However, in the case of electrons, this reconstruction procedure gives a poor estimation of the track parameters, because these particles lose a large amount of their energy through bremsstrahlung in the tracker material, and a reduced hit-collection efficiency.
For this reason, a dedicated tracking procedure has been developed for electrons \cite{ref76}.
 
The reconstruction of their track inside the silicon detectors starts with the generation of the track seeds from 2 or 3 hits in the pixel detector, combined with the positions of the vertices measured from the general charged particle tracks.\\ 
To select the seeds, two complementary algorithms are used, and their results are combined at the end. These algorithms are the following:
\begin{itemize}
	\item \textbf{ECAL-based seeding}: The SC energy and position are used to extrapolate the electron trajectory towards the inner layers of the tracker. If a reconstructed tracker seed, that matches the prediction from the SC, is found, it is selected.
	\item \textbf{Tracker-based seeding}: The tracker tracks reconstructed using the Kalman filter algorithm are extrapolated towards the ECAL and matched to a SC.
\end{itemize}

The first algorithm provides better results for high $\mathrm{p_{T}}$ electrons, while the second one is optimized from low $\mathrm{p_{T}}$ electrons, when the bremsstrahlung is negligible. The seeds obtained with these two algorithms are then merged into a unique collection.\\
The significant increase of the seeding efficiency brought by the tracker-based approach is shown in Fig. \ref{fig:Electron_Eff} for electrons in b quark jets.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{Electron_Eff}
	\caption{Electron seeding efficiency for electrons (triangles) and pions (circles) as a function of $\mathrm{p_{T}}$. Both the efficiencies for ECAL-based seeding only (hollow symbols) and with the tracker-based seeding added (solid symbols) are displayed \cite{ref60}.}
	\label{fig:Electron_Eff}
\end{figure}

\subsection{Tracking}
The seeds selected in the previous step are used to build electron tracks: starting from them, a combinatorial track finding algorithm iteratively adds successive layers, taking into account their energy losses due to ionization and bremsstrahlung, modelled with the Bethe-Heitler (BH) formula \cite{ref74}.
Since the distribution of the energy loss in the BH model is non-Gaussian, the KF algorithm can no longer be used and it is substituted by a \emph{Gaussian Sum Filter} (GSF) algorithm \cite{ref75}. The GSF models the energy loss distribution as a sum of six Gaussian distributions with different mean, width and amplitude.

\subsection{Association track-cluster}
Electrons candidates are finally reconstructed by associating a GSF track to a cluster in the ECAL, using not very restrictive criteria.
For the matching of ECAL-driven tracks are used the SC reconstructed using either the hybrid or the multi-5$\times$5 algorithm. 
For the Tracker-driven tracks whereas, a boosted decision tree (BDT)\cite{ref117a} is used in combining the track observables and the SC observables to get a global identification variable.

\section{Jets reconstruction}
At LHC quarks and gluons are dominantly produced. However, due to the QCD confinement, they cannot be observed directly, but they fragment to a collimated bunch of hadrons flying roughly in the same direction, which is called “jet”. 
Their signature is an energy deposit in the calorimeters, along with a series of hits in the tracker, in case of charged hadrons. 

Jets are a background for several physics analysis, therefore is fundamental to reconstruct them properly \cite{ref77}.
For this purpose, the socalled \emph{anti-k$_{T}$ clustering algorithm} \cite{ref78} is used.

In the jet reconstruction the information from the different subdetectors can be combined together in different ways, according to the particular characteristics of the jets, that can therefore be divided in:
\begin{itemize}
	\item \textbf{Calorimeter jets}: they are reconstructed from energy deposits in the calorimeters (ECAL and HCAL) alone. 
	\item \textbf{Jet-plus-track (JPT) jets}: the tracker information is added to the calorimeters one to reconstruct the jets.
	\item \textbf{Particle Flow jets}: they are reconstructed taking as input the PF candidate particles and by clustering their four-momentum vectors. This greatly improves the jet momentum and spatial resolution with respect to calorimeter jets.
\end{itemize}

The anti-k$_{T}$ algorithm clusters either all particles reconstructed by the PF algorithm (PF jets), or the sum of the ECAL and HCAL energies deposited in the calorimeter towers (Calo jets), or all stable particles produced by the event generator excluding neutrinos (Ref jets).  Each PF (Calo) jet is matched to the closest Ref jet in the ($\eta$, $\phi$) plane, with $\Delta R <$ 0.1 (0.2). The improved angular resolution for PF jets is mainly due to the precise determination of the charged-hadron directions and momenta. In calorimeter jets, the energy deposits of charged hadrons are spread along the $\phi$ direction by the magnetic field, leading to an additional degradation of the azimuthal angular resolution.
%distance parameter of R = 0.4 is used for $\sqrt{s}$ = 13 TeV proton-proton collisions. 

In Fig. \ref{fig:PF_Jets} a simulated dijet event is displayed and it is possible to compare the improvement in jet reconstruction provided by the PF jets with respect to the Calo jets.\\

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.25]{PF_Jets}
	\caption{Jet reconstruction in a simulated dijet event.The particles clustered in the two PF jets are displayed with a thicker line. The PF jet $\mathrm{p_{T}}$, indicated as a radial line, is compared to the $\mathrm{p_{T}}$ of the corresponding generated (Ref) and calorimeter (Calo) jets. The four-momentum of the jet is obtained by summing the four-momenta of its constituents \cite{ref60}.}
	\label{fig:PF_Jets}
\end{figure}

\newpage
\chapter{Analysis }

\section{Theorical intro}

Belle \cite{ref102}
BaBar \cite{ref103}
LHCb \cite{ref107}
ATLAS \cite{ref108}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{FD_SM}
	\caption{FD/SM.}
	\label{fig:FD_SM}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{FD_BSM}
	\caption{FD/BSM.}
	\label{fig:FD_BSM}
\end{figure}

\section{Preliminary considerations}
\subsection{Production of $\tau$ leptons at LHC}

The expected inclusive number of $\tau$ coming from different processes are reported in Tab. \ref{tab:ExpectedTau}. 

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|l|c|}
	\hline 
	$\mathrm{Process1}$		&	$\mathrm{Process2}$& 	$\mathrm{N.\ of\ \tau\ for\ L = ? }$\\ \hline \hline
	$pp\rightarrow c\bar{c}+...$	&	$D\rightarrow \tau\nu_{\tau}$	&	000\\
	 &	(95\% $D_{s}$, 5\% $D^{\pm}$)	&	\\  \hline
	\multirow{2}{*}{$pp\rightarrow b\bar{b}+...$}		&	$B\rightarrow \tau\nu_{\tau}+...$	&	000\\
	 &	(44\% $B^{\pm}$, 45\% $B^{0}$, 11\% $B_{s}^{0}$)	&	\\
	&	$B\rightarrow D(\tau\nu_{\tau})+...$	&	000\\ 
	 &	(98\% $D_{s}$, 2\% $D^{\pm}$)	&	\\ \hline \hline
	$pp\rightarrow W+...$	&	$W\rightarrow\tau\nu_{\tau}+...$	&	000\\
	$pp\rightarrow Z+...$	&	$Z+...\rightarrow\tau\tau+...$	&	000\\ 
	\hline
	\end{tabular}
	\caption{List of processes from which $\tau$ leptons are produced, with their corresponding expected inclusive number for L = ? // The charge-conjugated states are included. }
	\label{tab:ExpectedTau}
\end{table}



The relative $\tau$ yields are listed in Tab. \ref{tab:relativeTauYield}.

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|c|c|c|c|}
	\hline 
	$\mathrm{Mother\ meson}$ 	& 	$\mathrm{Quark\ composition}$	&	$\mathrm{Meson\ mass\ (GeV)}$	&	$\mathrm{Relative\ \tau\ yield}$\\ \hline \hline
	$D_{s}$	&	$c\bar{s}$	&	1.97	&	72\%\\
	$D^{+}$	&	$c\bar{d}$	&	1.87	&	3\%\\
	$B^{+}$	&	$\bar{b}u$	&	5.28	&	11\%\\
	$B^{0}$	&	$\bar{b}d$	&	5.28	&	11\%\\
	$B_{s}$		&	$\bar{b}s$	&	5.37	&	3\%\\ 
	\hline
	\end{tabular}
	\caption{List of mesons from which $\tau$ are produced with the relative tau yields. The charge-conjugated states are included. }
	\label{tab:relativeTauYield}
\end{table}


\subsection{Signal acceptance}

\section{Outline: search strategy}

\section{Data and MonteCarlo samples}
\subsection{Datasets}
For the analysis described in this thesis, I have used data collected by CMS in pp collisions at a center of mass energy $\sqrt{s}$ = 13 TeV during Run II in the whole 2017.\\ 
These datasets are listed in Tab. \ref{tab:2017datasets}.\\
They correspond to a total integrated luminosity: $\mathcal{L} = 41.49\ fb^{-1}$.\\

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|c|c|}
	\hline 
	$\mathrm{2017\ Datasets}$ 	& 	$\mathrm{Run\ range}$	&	$\mathrm{Integr.\ Luminosity\ (fb^{-1})}$\\ \hline \hline
	/DoubleMuonLowMass/Run2017B-17Nov2017-v1/AOD	&	000							&	4.79\\
	/DoubleMuonLowMass/Run2017C-17Nov2017-v1/AOD	&	000							&	9.63\\
	/DoubleMuonLowMass/Run2017D-17Nov2017-v1/AOD	&	000							&	4.25\\
	/DoubleMuonLowMass/Run2017E-17Nov2017-v1/AOD	&	000							&	9.30\\
	/DoubleMuonLowMass/Run2017F-17Nov2017-v1/AOD	&	000							&	13.52\\ \hline
	Whole 2017 data															&	000							&	41.49\\
	\hline
	\end{tabular}
	\caption{Datasets of the whole 2017 data-taking that have been used for the analysis described in this thesis.}
	\label{tab:2017datasets}
\end{table}

The json file used for data processing is:\\
$\mathrm{Collisions17/13TeV/ReReco/Cert_294927-306462_13TeV_EOY2017ReReco_Collisions17_JSON_v1.txt}$.

\subsection{MonteCarlo samples}

The MC samples used in this analysis are listed in Tab. \ref{tab:MCsamples}.

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	$\mathrm{Simulated\ process}$ 	& 	$\mathrm{MC\ Dataset\ name}$	&	$\mathrm{N. events\ (M)}$\\ \hline \hline
	$\mathrm{D_{s}\rightarrow\tau \nu_{\tau}\rightarrow 3\mu\ \nu_{\tau}}$	&	$\mathrm{/DsToTau_To3Mu_MuFilter_TuneCUEP8M1_13TeV-pythia8/RunIIFall17DRPremix-PU2017_94X_mc2017_realistic_v11-v1/AODSIM}$	&	000\\
	$\mathrm{B^{0}\rightarrow\tau \nu_{\tau}\rightarrow 3\mu\ \nu_{\tau}}$	&	$\mathrm{/BuToTau_To3Mu_MuFilter_TuneCUEP8M1_13TeV-pythia8/RunIISummer16DR80Premix- PUMoriond17_80X_mcRun2_asymptotic_2016_TrancheIV_v6-v1/AODSIM}$	&	000\\
	$\mathrm{B^{\pm}\rightarrow\tau \nu_{\tau}\rightarrow 3\mu\ \nu_{\tau}}$	&	$\mathrm{/BdToTau_To3Mu_MuFilter_TuneCUEP8M1_13TeV-pythia8/RunIISummer16DR80Premix PUMoriond17_80X_mcRun2_asymptotic_2016_TrancheIV_v6-v1/AODSIM}$	&	000\\
	$\mathrm{D_{s}\rightarrow\phi \pi \rightarrow 2\mu\ \pi}$	&	$\mathrm{/DsPhiPi/fsimone-crab_crab_DsPhiPi_13TeV_RECO- c3763c515b5d7d94a8137c090655e1bb/USER\ PRIVATE}$	&	000\\
	\hline
	\end{tabular}
	\caption{MC samples used for the analysis described in this thesis.}
	\label{tab:MCsamples}
\end{table}


The branching fractions of the B and D mesons decays are listed in Tab. \ref{tab:MesonsBR}.
\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|r|c|}
	\hline
	$\mathrm{Process}$ 	& 	$\mathrm{Branching\ ratio (BR)}$	&	$\mathrm{Reference}$\\ \hline \hline
	$\mathrm{D_{s}\rightarrow\tau \nu_{\tau}}$	&	5.48 $\pm$ 0.23\%	&	PDG \cite{ref112}\\
	$\mathrm{B^{+}\rightarrow\tau \nu_{\tau} D_{0}^{*}}$	&	2.7 $\pm$ 0.3\%	&	PDG \cite{ref112}\\
	$\mathrm{other B^{+}\rightarrow\tau \nu_{\tau} X}$	&	0.7\%	&	PYTHIA \cite{ref104}\\
	$\mathrm{B^{0}\rightarrow\tau \nu_{\tau} D^{+*}}$	&	2.7 $\pm$ 0.3\%	&	PDG \cite{ref112}\\
	$\mathrm{other B^{0}\rightarrow\tau \nu_{\tau} X}$	&	0.7\%	&	PYTHIA \cite{ref104}\\
	$\mathrm{B^{+}\rightarrow D_{s} X}$	&	9.0 $\pm$ 1.5\%		&	PDG \cite{ref112}\\
	$\mathrm{B^{0}\rightarrow D_{s} X}$		&	10.3 $\pm$ 2.1\%		&	PDG \cite{ref112}\\
	$\mathrm{D_{s}\rightarrow \phi(\mu\mu)\pi}$	&	1.3($\pm$ 0.1 $\cdot 10^{-5}$)	&	PDG \cite{ref112}\\
	\hline
	\end{tabular}
	\caption{MC samples used for the analysis described in this thesis.}
	\label{tab:MesonsBR}
\end{table}

\section{Event selection}

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|cc|c|}
	\hline
		 	& 	\multicolumn{2}{c|}{Signal}	&	Data\\
		 	&	$D_{s}\rightarrow\tau\nu_{\tau}$	&	$B^{\pm}/B^{0}\rightarrow\tau...$	&	 \\ \hline 	
	Produced in pp collisions	&	000	&	000	&	 \\
		(with three muons in fiducial volume)	&	000	&	000	&	 \\
	L1/HLT trigger	&	000	&	000	&	  \\
	At least 3 GlobalMuon ($\mathrm{p_{T}} >$ 2 GeV)	&	000	&	000	&	 000\\
	Trimuon candidate selection	&	000	&	000	&	 000\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:NEvents}
\end{table}

The PRE-selections applied to choose the interesting (DsTau3Mu) events are the following:
\begin{enumerate}
	\item Fired HLT : at least one HLT path among 
		\begin{itemize}
			\item $\mathrm{HLT\_DoubleMu3\_Trk\_Tau3mu\_v*}$
			\item $\mathrm{HLT\_DoubleMu3\_TkMu\_DsTau3Mu\_v*}$
			\item $\mathrm{HLT\_DoubleMu3\_Trk\_Tau3mu\_NoL1Mass\_v*}$
		\end{itemize}
	\item At least 3 muons with :
		\begin{itemize}
			\item $\mathrm{p_{T}\ >\ 0.5}$
			\item $\mathrm{|\eta|\ <\ 2.4}$
			\item innerTrack().isNonnull
			\item charge $\neq$ 0
			\item innerTrack().hitPattern().numberOfValidPixelHits()$>$ 0
		\end{itemize}
	\item At least 1 triplet with $\mathrm{|charge|}$ = 1
\end{enumerate}

The selections applied on the triplets to choose the interesting (DsTau3Mu) ones are the following:
\begin{enumerate}
	\item The $\chi^2$ of the triplet vertex is in (0-15)
	\item The 3 possible pairs of mu of the triplet have $\Delta R <$ 0.8
	\item The 3 possible pairs of mu of the triplet have $|\Delta Z| <$ 0.5
	\item VETO on mass of o.s. muons of the triplet compatible with $\phi$ meson
	\item VETO on mass of o.s. muons of the triplet compatible with $\omega$ meson
	\item Mass window ??
	\item L1 ???
	\item trigger matching requirements
\end{enumerate}
If more than one triplet per event survives, it’s chosen the one with the best (min) $\chi^2$ value.

\section{Signal Normalization}
\subsection{Events triggered by DoubleMu L1 seeds}
\begin{equation}
\mathrm{N_{sig(D)}} = \mathcal{L}\ \sigma(pp \rightarrow D_{s})\ \mathcal{B}(D_{s} \rightarrow \tau \nu_{\tau})\ \mathcal{B}(\tau \rightarrow 3\mu)\ \mathcal{A}_{3\mu(D)}\ \epsilon^{3\mu}_{reco}\ \epsilon^{2\mu}_{trig}
\end{equation}

\begin{equation}
\mathrm{N} = \mathcal{L}\ \sigma(pp \rightarrow D_{s})\ \mathcal{B}(D_{s} \rightarrow \phi \pi \rightarrow \mu \mu \pi)\ \mathcal{A}_{2\mu\pi}\ \epsilon^{2\mu\pi}_{reco}\ \epsilon^{2\mu}_{trig}
\end{equation}

\begin{equation}
\mathrm{N_{sig(D)}} = N\ \cdot\frac{\mathcal{B}(D_{s} \rightarrow \tau \nu_{\tau})}{\mathcal{B}(D_{s} \rightarrow \phi \pi \rightarrow \mu \mu \pi)}\ \frac{\mathcal{A}_{3\mu(D)}}{\mathcal{A}_{2\mu\pi}}\ \frac{\epsilon^{3\mu}_{reco}}{\epsilon^{2\mu\pi}_{reco}}\ \mathcal{B}(\tau \rightarrow 3\mu)
\end{equation}

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|c|c|c|}
	\hline
	$\mathrm{ Run}$ 	& 	$\mathrm{Fitted\ D_{s}\rightarrow\phi(\mu\mu)\pi\ yields\ (fb^{-1})}$	&	$\mathrm{Data/MC\ ratio}$\\ \hline 
	2017 B	&	000	&	000\\
	2017 C	&	000	&	000\\
	2017 D	&	000	&	000\\
	2017 E	&	000	&	000\\
	2017 F	&	000	&	000\\ \hline
	Whole 2017	&	000	&	000\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:N_Ds}
\end{table}

\subsection{B/D ratio}

\begin{equation}
\mathrm{N_{sig(B)}} = \mathcal{L}\ \sigma(pp \rightarrow B)\ \mathcal{B}(B \rightarrow \tau+...)\ \mathcal{B}(\tau \rightarrow 3\mu)\ \mathcal{A}_{3\mu(B)}\ \epsilon^{3\mu}_{reco}\ \epsilon^{2\mu}_{trig}
\end{equation}

\begin{equation}
f\ =\ \frac{\sigma(pp \rightarrow B)\ \mathcal{B}(B \rightarrow D_{s}+...)}{\sigma(pp \rightarrow D_{s})}
\end{equation}

\begin{equation}
\mathrm{N_{sig(B)}} = N \cdot\ f \cdot\ \frac{\mathcal{B}(B \rightarrow \tau+...)}{\mathcal{B}(D_{s} \rightarrow \phi \pi \rightarrow \mu \mu \pi)\ \mathcal{B}(B \rightarrow D_{s}+...)}\ \frac{\mathcal{A}_{3\mu(B)}}{\mathcal{A}_{2\mu\pi}}\ \frac{\epsilon^{3\mu}_{reco}}{\epsilon^{2\mu\pi}_{reco}}\ \mathcal{B}(\tau \rightarrow 3\mu)
\end{equation}

\subsection{Control channel} 
MC validation with $D_{s}\rightarrow\phi(\mu\mu)\pi$.

PRE-selections applied on the events:
\begin{enumerate}
	\item Fired HLT path: $HLT\_DoubleMu3\_Trk\_Tau3mu\_v*$
	\item at least 1 triplet with:
		\begin{itemize}
			\item 2 muons with:
				\begin{itemize}
					\item $\mathrm{p_{T}\ >\ 0.5}$
					\item  $\mathrm{|\eta|\ <\ 2.4}$
					\item innerTrack().isNonnull
					\item charge $\neq$ 0
					\item innerTrack().hitPattern().numberOfValidPixelHits() $>$ 0
				\end{itemize}
			\item 1 track with:
				\begin{itemize}
					\item $\mathrm{p_{T}\ >\ 2}$
					\item $\mathrm{|\eta|\ <\ 2.4}$
					\item charge $\neq$ 0
					\item hitPattern().trackerLayersWithMeasurement() $>$ 5
					\item hitPattern().pixelLayersWithMeasurement() $\geq$ 1
				\end{itemize}					
		\end{itemize}
	\item the triplet must have:
		\begin{itemize}
			\item mass in (0.5 - 10) GeV
			\item $\mathrm{|charge|}$ = 1
		\end{itemize}			
\end{enumerate}

The selections applied on the triplets are:
\begin{enumerate}
	\item L1 trigger trigger fired: $L1\_DoubleMu0er1p5\_SQ\_OS\_dR\_Max1p4$
	\item the 2 muons are global and different from the track
	\item the $\chi^2$ of the triplet vertex is in [0,15]
	\item the 2 muons have opposite charge
	\item the 2 muons invariant mass is in [1, 1.04] GeV
	\item the longitudinal IP $<$ 20 cm and the transverse IP $<$ 0.3 cm
	\item trigger matching requirements:
		\begin{itemize}
			\item $\mathrm{Mu01\_dRtriggerMatch\ <\ 0.03}$
			\item $\mathrm{Mu02\_dRtriggerMatch\ <\ 0.03}$
			\item $\mathrm{Tr\_dRtriggerMatch\ <\ 0.03}$
		\end{itemize}
\end{enumerate}
If more than one triplet per event survives, it’s chosen the one with the best (min) $\chi^2$ value.

\section{Multivariate Analysis (MVA)}
\subsection{Introduction to MVA: why to use it?}
The Multivariate analysis has assumed progressively a central role in high energy physics searches \cite{ref117b}. In this field, this kind of analysis aims to exploit as much information as possible from the characteristics of each event in order to distinguish between event types (eg. signal and background).\\
In order to understand how this analysis works and which are the improvements in using it with respect to "traditional" analysis performed by successive cuts, let's look at the scatter plots in Fig. \ref{fig:MVA_examples}. They show the distribution of two variables $x_{1}$ and $x_{2}$ which represent two out of a potentially large number of quantities measured for each event, with different decision boundaries (cuts, lineary boundary, non linear boundary). The signal events are indicated with blue circles while the red triangles represent the background ones. \\

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{MVA_examples}
	\caption{Scatter plots of two variables corresponding to two hypotheses: signal (blue) and background (red). Event selection could be based, e.g., on (a) cuts, (b) a linear boundary, (c) a nonlinear boundary.
  \cite{ref117b}.}
	\label{fig:MVA_examples}
\end{figure}

It is evident that rectangular and diagonal cuts are not as good as nonlinear boundaries in classifying the events. In general, the best decision boundary is a surface in the n-dimensional space of input variables, which can be represented by an equation of the form $y(\bm{x}) = y_{cut}$, where $y_{cut}$ is some constant. Events are classified as signal if they are on one side of the boundary, e.g., $y(\bm{x}) \leq y_{cut}$, could represent the acceptance region and $y(\bm{x}) > y_{cut}$ could be the rejection region.\\
- oppure utilizzo come "scalar test" statistics (vedi 14-15 Cowan per more details )

\subsection{Boosted Decision Tree (BDT)}
\subsubsection*{Decision Tree}
A decision tree is a binary tree structured classifier, defined by a collection of successive cuts on the set of input variables. It is schematically represented in Fig. \ref{fig:DecisionTree}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{DecisionTree}
	\caption{Scheme of a decision tree. A sequence of binary splits using the discriminating variables xi is applied to the data, starting from the root node. Each split uses the variable that, at that node, discriminates in the best way signal(S) and background(B). The leaf nodes at the bottom end of the tree are labeled (S or B) depending on the majority of events that end up in the respective nodes \cite{ref117}.}
	\label{fig:DecisionTree}
\end{figure}

Starting from the entire sample of training events in the root node, out of all of the possible input variables, one finds the ones that provide the best separation between signal and background by use of a single cut. Then, repeated left/right (yes/no) decisions are taken on one single variable at a time until a stop criterion is fulfilled. \\
In this way, the phase space is split into many regions that are eventually classified as signal or background, depending on the majority of training events that end up in the final leaf node. \\
Therefore, the difference of this classifier, with respect to the case of rectangular cuts, is that whereas a cut-based analysis is able to select only one hypercube as region of phase space, the decision tree is able to split the phase space into a large number of hypercubes, each of which is identified as either “signal-like” or “background-like”.
For classification trees, the path down the tree to each leaf node represents an individual cut sequence that selects signal or background depending on the type of the leaf node.

A shortcoming of decision trees is their instability with respect to statistical fluctuations in the training sample from which the tree structure is derived.\\
This problem can be overcome by using a Boosted Decision Tree.

\subsubsection*{Boosting the tree...}
The boosting of a decision tree extends this concept from one tree to several trees, which form a \emph{forest}. \\
The trees are derived from the same training ensemble by reweighting events (procedure called “boosting"), and are finally combined into a single classifier which is given by an average of the individual decision trees.
This boosting increases the statistical stability of the classifier and is able to drastically improve the separation performance compared to a single decision tree. \\
(In many cases, the boosting performs best if applied to trees that, taken individually, have not much classification power. These so called “weak classifiers” are small trees, limited in growth to a typical tree depth of as small as two, depending on the how much interaction there is between the different input variables. By limiting the tree depth during the tree building process (training), the tendency of overtraining for simple decision trees which are typically grown to a large depth and then pruned, is almost completely eliminated.)\\
A number of boosting algorithms have been developed, and these differ primarily in the rule used to update the weights; the one employed in the BDT used in this analysis is the so-called \emph{AdaBoost} (adaptive boost), which is explained in detail in \cite{ref117a}.

%\subsubsection*{Adaptive Boost (AdaBoost)}  
%In a classification problem, events that were misclassified during the training of a decision tree are given a higher event weight in the training of the following tree. 
%Starting with the original event weights when training the first decision tree, the subsequent tree is trained using a modified event sample where the weights of previously misclassified events are multiplied by a common boost weight $\alpha$. The boost weight is derived from the misclassification rate, err, of the previous tree (By construction, the error rate is err $\leq$ 0.5 as the same training events used to classify the output nodes of the previous tree are used for the calculation of the error rate.)
%
%\begin{equation}
%\alpha = \frac{1-err}{err}
%\end{equation}
%
%The weights of the entire event sample are then renormalised such that the sum of weights remains constant.
%We define the result of an individual classifier as $h(\bm{x})$, with ($\bm{x}$ being the tuple of input variables) encoded for signal and background as $h(\bm{x})$ = +1 and -1, respectively.\\ 
%The boosted event classification $y_{Boost}(\bm{x})$ is then given by
% 
%\begin{equation}
%y_{Boost}(\bm{x}) = \frac{1}{N_{collection}}\cdot\sum_{i}^{N_{collection}}\ ln(\alpha_{i})\cdot h_{i} (\bm{x})
%\end{equation}
%
% where the sum is over all classifiers in the collection. Small (large) values for yBoost(x) indicate a background-like (signal-like) event. Equation (the previous one) represents the standard boosting algorithm.
%AdaBoost performs best on weak classifiers, meaning small indivdidual decision trees with a tree depth of often as small 2 or 3, that have very little discrimination power by themselves. Given such small trees, they are much less prone to overtraining compared to simple decision trees and as an ensemble outperform them typically by far. The performance is often further enhanced by forcing a “slow learing” and allowing a larger number of boost steps instead. The learning rate of the AdaBoost algorithm is controled by a parameter $\beta$ giving as an exponent to the boost weight $\alpha\rightarrow\alpha^{\beta}$, which can be modified using the configuration option string of the MVA method to be boosted.

\subsubsection{Training a decision tree}
(ridurre: in molte parti è una ripetizione di quanto già detto! Accorpare al precedente!)

The training of a decision tree is the process that defines the splitting criteria for each node. It starts with the root node, where an initial splitting criterion for the full training sample is determined. The split results in two subsets of training events that each go through the same algorithm of determining the next splitting iteration. This procedure is repeated until the whole tree is built. At each node, the split is determined by finding the variable and corresponding cut value that provides the best separation between signal and background. The node splitting stops once it has reached the minimum number of events which is specified in the BDT configuration (option nEventsMin). The leaf nodes are classified as signal or background according to the class the majority of events belongs to. 
% If UseYesNoLeaf is set to false the end-nodes are classified according to their purity. (The purity of a node is given by the ratio of signal events to all events in that node. Hence pure background nodes have zero purity.)
A variety of separation criteria can be configured to assess the performance of a variable and a specific cut requirement. Because a cut that selects predominantly background is as valuable as one that selects signal, the criteria are symmetric with respect to the event classes. All separation criteria have a maximum where the samples are fully mixed, i.e., at purity p = 0.5, and fall off to zero when the sample consists of one event class only. 
%Tests have revealed no significant performance disparity between the following separation criteria:
%\begin{itemize}
%	\item Gini Index(default), defined by $p \cdot (1-p)$;
%	\item Cross entropy, defined by $-p\cdot\ ln\ (p)-(1-p)\cdot ln\ (1-p)$;
%	\item Misclassification error, defined by 1 - max(p, 1 - p);
%	\item Statistical significance, defined by S/$\sqrt{S + B}$
%	\item Average squared error, defined by $1/N \cdot \prod_{n}(y-\hat{y})^2$ for regression trees where y is the regression target of each event in the node and $\hat{y}$ is its mean value over all events in the node (which would be the estimate of y that is given by the node).
%\end{itemize}

Since the splitting criterion is always a cut on a single variable, the training procedure selects the variable and cut value that optimises the increase in the separation index between the parent node and the sum of the indices of the two daughter nodes, weighted by their relative fraction of events. The cut values are optimised by scanning over the variable range with a granularity that is set via the option nCuts. 

PROVARE!!! The default value of nCuts=20 proved to be a good compromise between computing time and step size. Finer stepping values did not increase noticeably the performance of the BDTs. However, a truly optimal cut, given the training sample, is determined by setting nCuts=-1. This invokes an algorithm that tests all possible cuts on the training sample and finds the best one. 

\subsubsection*{Variable ranking}
A ranking of the BDT input variables is derived by counting how often the variables are used to split decision tree nodes, and by weighting each split occurrence by the separation gain-squared it has achieved and by the number of events in the node.\\ 
This measure of the variable importance can be used for a single decision tree as well as for a forest.

\subsubsection*{Performance}
PUNTO a FAVORE: Decision trees are also insensitive to the inclusion of poorly discriminating input variables (which is not the case of neural networks, for example). 

Boosted decision trees have become increasingly popular in particle physics in recent years. One of their advantages is that they are relatively insensitive to the number of input variables used in the data vector x. Components that provide little or no separation between signal and background are rarely chosen as for the cut that provides separation, i.e., to split the tree, and thus they are effectively ignored. Decision trees have no difficulty in dealing with different types of data; these can be real, integer, or they can simply be labels for which there is no natural ordering (categorical data). Furthermore, boosted decision trees are surprisingly insensitive to overtraining. That is, although the error rate on the test sample will not decrease to zero as one increases the number of boosting iterations (as is the case for the training sample), it tends not to increase. Further discussion of this point can be found in \cite{ref117c}.
-- copia-e-incolla- END

- TMVA\\
The Toolkit for Multivariate Analysis (TMVA) provides a ROOT-integrated \cite{ref117} environment for the application of multivariate classification techniques.\\
All TMVA techniques belong to the family of \emph{supervised learning} algorithms. They make use of training events, for which the desired output is known, to determine the mapping function that describes a decision boundary (classification). This function can contain various degrees of approximations and may be a single global function, or a set of local models. \\
A typical TMVA classification consists of two independent phases: the \emph{training phase}, where the multivariate methods are trained, tested and evaluated, and an \emph{application phase}, where the chosen methods are applied to the concrete classification or regression problem they have been trained for.
 

\subsection{BDT training}
\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|c|}
	\hline
	Input variable	&	Importance	\\ \hline
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	var	&	000\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:BDT_ranking}
\end{table}

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|c|}
	\hline
	Parameter		&	Setting (default)	\\ \hline
	NTrees	&	800	\\
	nCuts	&	20	\\
	MaxDepth		&	3	\\
	BoostType	&	AdaBoost	\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:BDT_parameters}
\end{table}

\subsection{Event categorization}

\section{Evaluation of systematics}
Bla Bla \cite{ref118}

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	Source of uncertainty	& 	Yield		&	Shape\\ \hline 
	Uncertainty on $D_{s}$ normalization [ 3.5\% ]	&	000	&	 \\
	Uncertainty on measuring f (B/D ratio) [ 10\% ]	&	000	&	 \\
	Uncertainty on n. of events triggered by trimuon trigger [ 12\% ]	&	000	&	 \\
	Relative uncertainty in $\mathcal{B}(D_{s} \rightarrow\phi\pi\rightarrow\mu\mu\pi$) [ 8\% ]	&	000	&	 \\
	Relative uncertainty in $\mathcal{B}(D_{s}\rightarrow\mu\nu)$ [ 4\% ]	&	000	&	 \\
	Relative uncertainty in $\mathcal{B}(B\rightarrow D_{s} + ...)$ [ 16\% ]		&	000	&	 \\
	Relative uncertainty in $\mathcal{B}(B \rightarrow \tau + ...)$ [ 11\% ]	&	000	&	 \\
	Uncertainty on the ratio of acceptances $\mathcal{A}_{sig}\ /\ \mathcal{A}_{2\mu\pi}$ [ 1\% ]	&	000	&	 \\
	Muon reconstruction efficiency [ 1.5\% ]	&	000	&	 \\
	BDT cut efficiency [ 5\% ]	&	000	&	 \\
	Muon momentum scale uncertainty [ 0.2\% ]	&	-	&	yes \\
	Muon momentum resolution uncertainty [ 10\% ]	&	-	&	 yes\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:Uncertainties}
\end{table}

\section{Results}

\begin{equation}
q_{\mu} = -\mathrm{2\ ln}\ \frac{\mathcal{L}\ (\mathrm{obs|\ \mu\cdot s+b,\ \hat{\theta_{\mu}}})}{\mathcal{L}\ (\mathrm{obs|\ \hat{\mu}\cdot s+b,\ \hat{\theta}})}
\end{equation}

\begin{equation}
\mathcal{L}\mathrm{(data|\ \mu s+b)}\ \sim\ e^{-(\mu S+B)}\ \prod_{i}\mathcal{P}\mathrm{(x_{i}|\ \mu s+b)}
\end{equation}

\begin{equation}
\mathrm{CL_{s}\ =\ \frac{P\ (q_{\mu}\geq q_{\mu}^{obs}\ |\mu\cdot\ s+b)}{P\ (q_{\mu}\geq q_{\mu}^{obs}\ |\ b)}} \leq 0.1
\end{equation}

\begin{table}[h!]\footnotesize
	\centering
	\begin{tabular}{|c|cc|cc|}
	\hline
		 	& 	\multicolumn{2}{c|}{Signal}		&	\multicolumn{2}{c|}{Background}\\
		 	&	sub-category 1	&	sub-category 2	&	sub-category 1	&	sub-category 2\\ \hline 	
	Category A	&	000	&	000	&	000	&	000\\
	Category B	&	000	&	000	&	000	&	000\\
	Category C	&	000	&	000	&	000	&	000\\
	\hline
	\end{tabular}
	\caption{Bla Bla}
	\label{tab:Results}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\chapter*{Conclusions}


\begin{thebibliography}{90}             
%\addcontentsline{toc}{chapter}{Bibliografia}

% Ref cap1
	\bibitem{ref0} ROOT, \url{http://root.cern.ch}.
	% Higgs discovery
	\bibitem{ref1} ATLAS Collaboration, \emph{“Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC”}, Phys. Lett. B 716 (2012) 1, \href{https://www.sciencedirect.com/science/article/pii/S037026931200857X}{doi:10.1016/j.physletb.2012.08.020}, \href{https://arxiv.org/abs/1207.7214}{arXiv:1207.7214}.
	
	\bibitem{ref2} CMS Collaboration, \emph{“Observation of a new boson at a mass of 125 GeV with the CMS experiment at the LHC”}, Phys. Lett. B 716 (2012) 30, \href{https://www.sciencedirect.com/science/article/pii/S0370269312008581}{doi:10.1016/j.physletb.2012.08.021}, \href{https://arxiv.org/abs/1207.7235}{arXiv:1207.7235}.
	
	\bibitem{ref3} CMS Collaboration,\emph{“Observation of a new boson with mass near 125 GeV in pp collisions at $\sqrt{s}$ = 7 and 8 TeV”}, JHEP 1306 (2013) 081, \href{https://link.springer.com/article/10.1007/JHEP06(2013)081}{doi:10.1007/JHEP06(2013)081}, \href{https://arxiv.org/abs/1303.4571}{arXiv:1303.4571}.

	
	\bibitem{ref4}
	\bibitem{ref5}
	\bibitem{ref6}
	\bibitem{ref7}
	\bibitem{ref8}
	\bibitem{ref9}
	\bibitem{ref10}
	\bibitem{ref11}
	\bibitem{ref12}
	\bibitem{ref13}
	\bibitem{ref14}
	\bibitem{ref15}
	\bibitem{ref16}
	\bibitem{ref17}
	\bibitem{ref18}
	\bibitem{ref19}
	\bibitem{ref20}
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
% Ref cap2
	% LHC
	\bibitem{ref30} L. Evans and P. Bryant, \emph{“LHC Machine”}, JINST 3 (2008) S08001, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08001/meta}{doi:10.1088/1748- 0221/3/08/S08001}.
	% LEP
	\bibitem{ref31} \emph{“The Large Electron-Positron Collider”}, \url{http://cds.cern.ch/record/1997351, July 2012}.
	% CMS
	\bibitem{ref32} CMS Collaboration, \emph{”The CMS experiment at the CERN LHC”}, JINST 3 (2008) S08004, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08004}{doi:10.1088/1748-0221/3/08/S08004}.
	
	\bibitem{ref33} CMS Collaboration, \emph{”CMS Detector Performance and Software: Technical Design Report”}, 2006. CERN/LHCC 2006-001, CMS TDR 8.1, \url{https://cdsweb.cern.ch/record/922757/files/lhcc-2006-001.pdf}.
	% ATLAS
	\bibitem{ref34} ATLAS Collaboration, \emph{“The ATLAS Experiment at the CERN Large Hadron Collider”}, JINST 3 (2008) S08003, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08003/meta}{doi:10.1088/1748-0221/3/08/S08003}.
	% ALICE
	\bibitem{ref35} ALICE Collaboration, \emph{“The ALICE experiment at the CERN LHC”}, JINST 3 (2008) S08002, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08002/meta}{doi:10.1088/1748-0221/3/08/S08002}.
	% LHCb
	\bibitem{ref36} LHCb Collaboration, \emph{“The LHCb Detector at the LHC”}, JINST 3 (2008) S08005, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08005/meta}{doi:10.1088/1748-0221/3/08/S08005}.
	% LUMI public results
	\bibitem{ref37} CMS Collaboration, \emph{“CMS Luminosity - Public Results”}, \url{https://twiki.cern.ch/twiki/bin/view/CMSPublic/LumiPublicResults}.
	
	% Magnet
	\bibitem{ref44} CMS Collaboration, \emph{“The CMS magnet project: Technical Design Report”},1997. CERN/LHCC 97-010, CMS TDR 1, \url{http://cds.cern.ch/record/331056?ln=it}.
	
	\bibitem{ref38} CMS Collaboration, \emph{“Precise Mapping of the Magnetic Field in the CMS Barrel Yoke using Cosmic Rays”}, JINST 5 (2010) T03021, \href{https://iopscience.iop.org/article/10.1088/1748-0221/5/03/T03021/meta}{doi:10.1088/1748- 0221/5/03/T03021}.
	%Tracker
	\bibitem{ref39} CMS Collaboration, \emph{“The CMS tracker system project: Technical Design Report”},1998. CERN/LHCC 98-006, CMS TDR 5, \url{http://cdsweb.cern.ch/record/368412}.
	
	\bibitem{ref40} CMS Collaboration, \emph{“The CMS tracker: addendum to the Technical Design Report"},2000. CERN/LHCC 2000-016, CMS TDR 5.1, \url{http://cdsweb.cern.ch/record/490194}.
	
	\bibitem{ref41} CMS Collaboration, \emph{“CMS Tracking Performance Results from early LHC Operation”}, Eur. Phys. J. C 70 (2010) 1165, \href{https://link.springer.com/article/10.1140/epjc/s10052-010-1491-3}{doi:10.1140/epjc/s10052- 010-1491-3}, \href{https://arxiv.org/abs/1007.1988}{arXiv:1007.1988}.
	% Calo
	\bibitem{ref42} CMS Collaboration, \emph{“The Electromagnetic Calorimeter Project: Technical Design Report”}, 1997. CERN/LHCC 97-33, CMS TDR 4, \url{http://cds.cern.ch/record/349375?ln=it}.
	
	\bibitem{ref43} CMS Collaboration, \emph{“The hadron calorimeter project: technical design report”}, 1997. CERN/LHCC 97-031, CMS TDR 2, \url{http://cdsweb.cern.ch/record/357153}.
	% Muon system
	\bibitem{ref45} CMS Collaboration, \emph{“The muon project: Technical Design Report”},1997. CERN/LHCC 97-032, CMS TDR 3, \url{http://cdsweb.cern.ch/record/343814}.	
	
	\bibitem{ref46} CMS Collaboration, \emph{“Performance of the CMS muon detector and muon reconstruction with proton-proton collisions at $\sqrt{s}$ = 13 TeV"}, JINST 13 (2018) P06015, \href{https://iopscience.iop.org/article/10.1088/1748-0221/13/06/P06015}{doi:10.1088/1748-0221/13/06/P06015}, \href{https://arxiv.org/abs/1804.04528}{arXiv:1804.04528}.
	
	\bibitem{ref47} CMS Collaboration, \emph{“Performance of the CMS Muon Detectors in 2016 collision runs”}, CERN-CMS-DP-2016-046, \url{https://cds.cern.ch/record/2202964}.
	% Trigger
	\bibitem{ref48} CMS Collaboration, \emph{“CMS TriDAS project: Technical Design Report, Volume 1: The Trigger Systems”},2000. CERN/LHCC 2000-038, CMS TDR 6.1, \url{http://cds.cern.ch/record/706847?ln=it}.
	
	\bibitem{ref49} CMS Collaboration, \emph{“CMS The TriDAS Project: Technical Design Report, Volume 2: Data Acquisition and High-Level Trigger”},2002. CERN/LHCC 2002-026, CMS TDR 6, \url{http://cds.cern.ch/record/578006?ln=it}.
	
	\bibitem{ref50} CMS Collaboration, \emph{“CMS computing: Technical Design Report”},2005. CERN/LHCC 2005-023, CMS TDR 7, \url{http://cds.cern.ch/record/838359?ln=it}.
	
	\bibitem{ref51}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
% Ref cap3
	% PF
	\bibitem{ref60} CMS Collaboration, \emph{“Particle-flow reconstruction and global event description with the CMS detector”}, JINST 12 (2017) P10003, \href{https://iopscience.iop.org/article/10.1088/1748-0221/12/10/P10003/pdf}{doi:10.1088/1748- 0221/12/10/P10003}, \href{https://arxiv.org/abs/1706.04965}{arXiv:1706.04965}.
	% MET
	\bibitem{ref61} CMS Collaboration,\emph{“Missing transverse energy performance of the CMS detector”}, JINST 16 (2011) P09001, \href{https://iopscience.iop.org/article/10.1088/1748-0221/6/09/P09001}{doi 10.1088/1748-0221/6/09/P09001}, \href{https://arxiv.org/abs/1106.5048}{arXiv:1106.5048}.
	% Tracker
	\bibitem{ref62} CMS Collaboration, \emph{“Description and performance of track and primary-vertex reconstruction with the CMS tracker”}, JINST 9 (2014) P10009, \href{https://iopscience.iop.org/article/10.1088/1748-0221/9/10/P10009/meta}{doi:10.1088/1748-0221/9/10/P10009}, \href{https://arxiv.org/abs/1405.6569}{arXiv:1405.6569}.
	
	\bibitem{ref62a}  CMS Collaboration, \href{https://twiki.cern.ch/twiki/bin/view/CMSPublic/TrackingPOGResults2017}{CMS Tracking POG Performance Plots for 2017 Dataset}.	
	
	% Kalman Filter
	\bibitem{ref66} Kalman, R. E., \emph{“A New Approach to Linear Filtering and Prediction Problems”}, Journal of Basic Engineering, vol. 82, p. 35, 1960, \href{http://www.unitedthc.com/DSP/Kalman1960.pdf}{doi:10.1115/1.3662552}.
	
	\bibitem{ref63} P. Billoir, \emph{“Progressive track recognition with a Kalman like fitting procedure”}, Comput. Phys. Commun. 57 (1989) 390, \href{https://www.sciencedirect.com/science/article/pii/001046558990249X}{doi: 10.1016/0010-4655(89)90249-X}.
	
	\bibitem{ref64} P. Billoir and S. Qian, \emph{“Simultaneous pattern recognition and track fitting by the Kalman filtering method”}, Nucl. Instrum. Meth. A 294 (1990) 219, \href{https://www.sciencedirect.com/science/article/pii/016890029091835Y}{doi:10.1016/0168-9002(90)91835-Y}.
	
	\bibitem{ref65} R. Fruhwirth, \emph{“Application of Kalman filtering to track and vertex fitting”}, Nucl. Instrum. Meth. A 262 (1987) 444, \href{https://www.sciencedirect.com/science/article/pii/0168900287908874}{doi:10.1016/0168-9002(87)90887-4}.
	% Vertex
	\bibitem{ref68} R. Fruhwirth, W. Waltenberger and P. Vanlaer, \emph{“Adaptive Vertex Fitting”}, J. Phys. G: Nucl. Part. Phys. 34 N343 (2007), \href{https://iopscience.iop.org/article/10.1088/0954-3899/34/12/N01}{doi.org/10.1088/0954-3899/34/12/N01}.
	% Muons
	% vedi ref 46
	\bibitem{ref69} CMS Collaboration, \emph{“Performance of CMS muon reconstruction in pp collision events at $\sqrt{s}$ = 7 TeV”}, JINST 7 (2012) P10002, \href{https://iopscience.iop.org/article/10.1088/1748-0221/7/10/P10002/meta}{doi 10.1088/1748- 0221/7/10/P10002}, \href{https://arxiv.org/abs/1206.4071}{arXiv 1206.4071}.
	
	\bibitem{ref70} CMS Collaboration, \href{https://cds.cern.ch/record/2629364/files/DP2018_042.pdf}{Muon identification and isolation efficiencies with 2017 and 2018 data}.
	
	% Electrons
	\bibitem{ref72} S. Baffioni et al., \emph{“Electron reconstruction in CMS”}, Eur.Phys.J., vol. C49, p. 1099, 2007, \href{https://link.springer.com/article/10.1140\%2Fepjc\%2Fs10052-006-0175-5}{doi:10.1140/epjc/s10052-006-0175-5}.
		
	\bibitem{ref71} CMS Collaboration, \emph{“Performance of electron reconstruction and selection with the CMS detector in proton-proton collisions at sqrt(s) =8 TeV}”, JINST 10 (2015) no.06, P06005, \href{https://arxiv.org/abs/1502.02701}{arXiv:1502.02701}.
	
	\bibitem{ref73} Khachatryan, Vardan and others, \emph{“Electron and photon performance in CMS with the full 2016 data sample”}, CMS-DP-2017-004, CERN-CMS-DP-2017-004, \url{https://cds.cern.ch/record/2255497/?ln=it}.
	
	 \bibitem{ref74} H. Bethe and W. Heitler, \emph{“On the Stopping of fast particles and on the creation of positive electrons”}, Proc.Roy.Soc.Lond., vol. A146, p. 83, 1934, \href{https://doi.org/10.1098/rspa.1934.0140}{doi:10.1098/rspa.1934.0140}.
	
	\bibitem{ref75} W.Adam, R.Fruhwirth, A.Strandlie, and T.Todorov, \emph{“Reconstruction of electrons with the Gaussian-sum filter in the CMS tracker at LHC”}, J. Phys. G 31 (2005) N9, \href{https://iopscience.iop.org/article/10.1088/0954-3899/31/9/N01/meta}{doi:10.1088/0954-3899/31/9/N01}, \href{https://arxiv.org/abs/physics/0306087}{arXiv:physics/0306087}.
	
	\bibitem{ref76} CMS Collaboration, \emph{"CMS Electron and Photon Performance at 13 TeV"}, 2019 J. Phys.: Conf. Ser. 1162 012008, \href{https://iopscience.iop.org/article/10.1088/1742-6596/1162/1/012008}{doi:10.1088/1742-6596/1162/1/012008}.
	% Jets
	\bibitem{ref77} Sirunyan, Albert M and others, \emph{“Identification of heavy-flavour jets with the CMS detector in pp collisions at 13 TeV ”}, JINST, 13 (2018) P05011, \href{https://iopscience.iop.org/article/10.1088/1748-0221/13/05/P05011/meta}{doi: 10.1088/1748- 0221/13/05/P05011}, \href{https://arxiv.org/abs/1712.07158}{arXiv:1712.07158}.
	
	\bibitem{ref78} M. Cacciari, G. P. Salam, and G. Soyez, \emph{“The anti-kt jet clustering algorithm”}, JHEP, vol. 0804, 2008, \href{https://iopscience.iop.org/article/10.1088/1126-6708/2008/04/063}{doi:10.1088/1126-6708/2008/04/063}, \href{https://arxiv.org/abs/0802.1189}{arXiv:0802.1189}.
	
	\bibitem{ref79}
	
		
% Ref Analysis Note	
	\bibitem{ref100} X.-Y. Pham, \emph{“Lepton flavor changing in neutrinoless tau decays”}, Eur. Phys. J. C 8 (1999) 513–516, \href{https://link.springer.com/article/10.1007\%2Fs100529901088}{doi:10.1007/s100529901088}, \href{https://arxiv.org/abs/hep-ph/9810484}{ arXiv:hep-ph/9810484}.
	
	\bibitem{ref101} W. J. Marciano, T. Mori, and J. M. Roney, \emph{“Charged Lepton Flavor Violation Experiments”}, Ann. Rev. Nucl. Part. Sci. 58 (2008) 315, \href{https://www.annualreviews.org/doi/10.1146/annurev.nucl.58.110707.171126}{doi:10.1146/annurev.nucl.58.110707.171126}.

	\bibitem{ref99} S. Mihara, J. P. Miller, P. Paradisi, and G. Piredda, \emph{“Charged Lepton Flavor-Violation Experiments”}, Ann. Rev. Nucl. Part. Sci. 63 (2013) 531–552, \href{https://www.annualreviews.org/doi/10.1146/annurev-nucl-102912-144530}{doi:10.1146/annurev-nucl-102912-144530}.

	\bibitem{ref102} Belle Collaboration, \emph{“Search for Lepton Flavor Violating Tau Decays into Three Leptons with 719 Million Produced Tau+Tau- Pairs”}, Phys. Lett. B 687 (2010) 139, \href{https://www.sciencedirect.com/science/article/pii/S0370269310003576?via\%3Dihub}{doi:10.1016/j.physletb.2010.03.037}, \href{https://arxiv.org/abs/1001.3221}{arXiv:1001.3221}.
	
	\bibitem{ref103} BaBar Collaboration, \emph{“Limits on tau Lepton-Flavor Violating Decays in three charged leptons”}, Phys. Rev. D 81 (2010) 111101, \href{https://journals.aps.org/prd/abstract/10.1103/PhysRevD.81.111101}{doi:10.1103/PhysRevD.81.111101}, \href{https://arxiv.org/abs/1002.4550}{arXiv:1002.4550}.
	
	\bibitem{ref104} T. Sjostrand, S. Mrenna, and P. Z. Skands, \emph{“A Brief Introduction to PYTHIA 8.1”}, Comput. Phys. Commun. 178 (2008) 852, \href{https://www.sciencedirect.com/science/article/pii/S0010465508000441?via\%3Dihub}{doi:10.1016/j.cpc.2008.01.036}, \href{https://arxiv.org/abs/0710.3820}{arXiv:0710.3820}.

	%\bibitem{ref105} LHCb Collaboration, \emph{“The LHCb Detector at the LHC”}, JINST 3 (2008) S08005, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08005}{doi:10.1088/1748-0221/3/08/S08005}. -- Già messo!
	
	%\bibitem{ref106} ATLAS Collaboration, \emph{“The ATLAS Experiment at the CERN Large Hadron Collider”}, JINST 3 (2008) S08003, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08003}{doi:10.1088/1748-0221/3/08/S08003}. -- Già messo!
	
	\bibitem{ref107} LHCb Collaboration, \emph{“Search for the lepton flavour violating decay $\tau^{-} \rightarrow \mu^{-}\mu^{+}\mu^{-}”$}, JHEP 02 (2015) 121, \href{https://link.springer.com/article/10.1007\%2FJHEP02\%282015\%29121}{doi:10.1007/JHEP02(2015)121}, \href{https://arxiv.org/abs/1409.8548}{arXiv:1409.8548}.
	
	\bibitem{ref108} ATLAS Collaboration, \emph{“Probing lepton flavour violation via neutrinoless $\tau\rightarrow 3\mu$ decays with the ATLAS detector”}, \href{https://arxiv.org/abs/1601.03567}{arXiv:1601.03567}.
	
	%\bibitem{ref109} CMS Collaboration, \emph{“The CMS experiment at the CERN LHC”}, JINST 3 (2008) S08004, \href{https://iopscience.iop.org/article/10.1088/1748-0221/3/08/S08004}{doi:10.1088/1748-0221/3/08/S08004}. -- Già messo!

	\bibitem{ref110} CMS Collaboration, \emph{“Event generator tunes obtained from underlying event and multiparton scattering measurements”}, Eur. Phys. J. C 76 (2016), no. 3, 155, \href{https://link.springer.com/article/10.1140\%2Fepjc\%2Fs10052-016-3988-x}{doi:10.1140/epjc/s10052-016-3988-x}, \href{https://arxiv.org/abs/1512.00815}{arXiv:1512.00815}.
	
	\bibitem{ref111} GEANT4 Collaboration, \emph{“GEANT4 — a simulation toolkit”}, Nucl. Instrum. Meth. A 506 (2003) 250, \href{https://www.sciencedirect.com/science/article/pii/S0168900203013688?via\%3Dihub}{doi:10.1016/S0168-9002(03)01368-8}.
	
	\bibitem{ref112} Particle Data Group Collaboration, \emph{“Review of Particle Physics”}, Phys. Rev. D 98 (2018), no. 3, 030001, \href{https://journals.aps.org/prd/abstract/10.1103/PhysRevD.98.030001}{doi:10.1103/PhysRevD.98.030001}. % AGGIORNALA !!!
	
	%\bibitem{ref113} CMS Collaboration, \emph{“Particle-flow reconstruction and global event description with the CMS detector”}, JINST 12 (2017) P10003, \href{https://iopscience.iop.org/article/10.1088/1748-0221/12/10/P10003}{doi:10.1088/1748-0221/12/10/P10003}, \href{https://arxiv.org/abs/1706.04965}{arXiv:1706.04965}.  -- Già messo!
	
	%\bibitem{ref114} CMS Collaboration, \emph{“Performance of the CMS muon detector and muon reconstruction with proton-proton collisions at $\sqrt{s}$=13 TeV"}, JINST 13 (2018) P06015, \href{https://iopscience.iop.org/article/10.1088/1748-0221/13/06/P06015}{doi:10.1088/1748-0221/13/06/P06015}, \href{https://arxiv.org/abs/1804.04528}{arXiv:1804.04528}. -- Già messo!
	
	\bibitem{ref115} CMS Collaboration, \emph{“Measurements of properties of the Higgs boson decaying into the four-lepton final state in pp collisions at $\sqrt{s}$ = 13 TeV"}, JHEP 11 (2017) 047, \href{https://link.springer.com/article/10.1007\%2FJHEP11\%282017\%29047}{doi:10.1007/JHEP11(2017)047}, \href{https://arxiv.org/abs/1706.09936}{arXiv:1706.09936}.
	
	\bibitem{ref116} CMS Collaboration, “Measurement of the inclusive W and Z production cross sections in pp collisions at $\sqrt{s}$= 7 TeV”, JHEP 10 (2011) 132, \href{https://link.springer.com/article/10.1007\%2FJHEP10\%282011\%29132}{doi:10.1007/JHEP10(2011)132}, \href{https://arxiv.org/abs/1107.4789}{arXiv:1107.4789}.

	\bibitem{ref117b} G. Cowan, \emph{“Topics in statistical data analysis for high-energy physics"}, CERN Yellow Report CERN-2010-002, pp.197-218, \href{https://arxiv.org/abs/1012.3589}{arXiv:1012.3589}.

	\bibitem{ref117} A. Hocker et al., \emph{“TMVA - Toolkit for Multivariate Data Analysis”}, PoS ACAT (2007)040, \href{https://arxiv.org/abs/physics/0703039}{arXiv:physics/0703039}.
	
	\bibitem{ref117a} Y. Freund and R.E. Schapire, \emph{“A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting"}, J. of Computer and System Science 55, 119 (1997), \href{https://www.sciencedirect.com/science/article/pii/S002200009791504X}{doi:10.1006/jcss.1997.1504}.
	
	\bibitem{ref117c} Y. Freund and R. E. Schapire, \emph{A short introduction to boosting}, J. Jpn. Soc. Artif. Intell. 14 (1999) 771–780, \url{https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf}.
	
	\bibitem{ref118} T. Junk, \emph{“Confidence level computation for combining searches with small statistics”}, Nucl. Instrum. Meth. A 434 (1999) 435, \href{https://www.sciencedirect.com/science/article/pii/S0168900299004982?via\%3Dihub}{doi:10.1016/S0168-9002(99)00498-2}.

	\bibitem{ref119} A. L. Read, \emph{“Presentation of search results: the CLs technique”}, J. Phys. G: Nucl. Part. Phys. 28 (2002) 2693, \href{https://iopscience.iop.org/article/10.1088/0954-3899/28/10/313}{doi:10.1088/0954-3899/28/10/313}.
	
\end{thebibliography}

\end{document}
